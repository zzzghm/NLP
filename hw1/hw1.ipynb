{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete this assignment, fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`, as well as your name below.\n",
    "\n",
    "To make sure everything runs as expected, do the following\n",
    "- **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart)\n",
    "- **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "A good introduction to Jupyter notebooks is [here](https://realpython.com/jupyter-notebook-introduction/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"JOY ZHUGE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e67e82f15b9da9033e570c3f93d1485",
     "grade": false,
     "grade_id": "jupyter",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# HW1 (50 points)\n",
    "\n",
    "In this assignment we will build classifiers to classify a movie review as positive or negative. Using labeled data from IMDb, we will explore how to tokenize each document, create feature vectors, and implement a few different classifiers. Our goal is to understand the overall process of classification using machine learning, as well as to understand how to measure the impact of different algorithmic choices.\n",
    "\n",
    "There are spaces below for you to both write code and short answers. In some places, there are tests to check your work, though passing tests does not guarantee full credit. I recommend moving sequentially from top to bottom, getting each step working before moving on to the next.\n",
    "\n",
    "This assignment will use a number of Python libraries, including `pandas`, `sklearn`, `matplotlib`, `seaborn`, `numpy`, and `scipy`. If you haven't already installed these, you can do so by running this command in this directory: `pip install -r requirements.txt`. Minor variants in the version numbers shouldn't affect things much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from collections import Counter\n",
    "import copy\n",
    "import numpy as np\n",
    "from numpy import array as npa\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import BernoulliNB,MultinomialNB\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5, rc={'figure.figsize':(12, 6)})\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "422752a91419f21fc5c1d3d46dfd41d8",
     "grade": false,
     "grade_id": "cell-a84e17035a9100b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Read and explore data\n",
    "\n",
    "First, we'll read in the data, compute some basic statistics over it, and review some syntax of Pandas.\n",
    "\n",
    "The training data is a tab-separated text file called `train.tsv`. We'll first read it into a Pandas [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). If you haven't used Pandas before, it is a handy library to read and manipulate tabular data. [Here](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html) is a nice overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Here's another movie that should be loaded into a satellite, fired into space and pointed in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>Cuban Blood is one of those sleeper films that has a lot to say about life in a very traditional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>This is not \"so bad that it is good,\" it is purely good! For those who don't understand why, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Both visually and musically stunning. A treat for both the eye and the ear. The quintessential V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "      <td>'Cry Freedom' is a movie about how far people will go to find the truth.&lt;br /&gt;&lt;br /&gt;The first ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>neg</td>\n",
       "      <td>This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>neg</td>\n",
       "      <td>...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>neg</td>\n",
       "      <td>This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>neg</td>\n",
       "      <td>I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>neg</td>\n",
       "      <td>Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  \\\n",
       "0     pos   \n",
       "1     pos   \n",
       "2     pos   \n",
       "3     pos   \n",
       "4     pos   \n",
       "..    ...   \n",
       "395   neg   \n",
       "396   neg   \n",
       "397   neg   \n",
       "398   neg   \n",
       "399   neg   \n",
       "\n",
       "                                                                                                    text  \n",
       "0    Here's another movie that should be loaded into a satellite, fired into space and pointed in the...  \n",
       "1    Cuban Blood is one of those sleeper films that has a lot to say about life in a very traditional...  \n",
       "2    This is not \"so bad that it is good,\" it is purely good! For those who don't understand why, you...  \n",
       "3    Both visually and musically stunning. A treat for both the eye and the ear. The quintessential V...  \n",
       "4    'Cry Freedom' is a movie about how far people will go to find the truth.<br /><br />The first ha...  \n",
       "..                                                                                                   ...  \n",
       "395  This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...  \n",
       "396  ...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...  \n",
       "397  This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...  \n",
       "398  I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...  \n",
       "399  Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...  \n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read training data into a Pandas DataFrame.\n",
    "train_df = pd.read_csv('train.tsv', sep='\\t')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    200\n",
       "neg    200\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so, there are 200 positive and 200 negative documents\n",
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Here's another movie that should be loaded into a satellite, fired into space and pointed in the...\n",
       "1      Cuban Blood is one of those sleeper films that has a lot to say about life in a very traditional...\n",
       "2      This is not \"so bad that it is good,\" it is purely good! For those who don't understand why, you...\n",
       "3      Both visually and musically stunning. A treat for both the eye and the ear. The quintessential V...\n",
       "4      'Cry Freedom' is a movie about how far people will go to find the truth.<br /><br />The first ha...\n",
       "                                                      ...                                                 \n",
       "395    This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...\n",
       "396    ...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...\n",
       "397    This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...\n",
       "398    I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...\n",
       "399    Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...\n",
       "Name: text, Length: 400, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can get a column, which is a pandas.Series object, like this:\n",
    "train_df.text  # or: train_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                                                                                                    pos\n",
       "text     This is a film which had eluded me thus far but, now that I've watched it, emerges as one of the...\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's the 11th row\n",
    "train_df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row number: 0\n",
      "label: pos\n",
      "text: Here's another movie that should be loaded into a satellite, fired into space and pointed in the dir\n"
     ]
    }
   ],
   "source": [
    "# here's how we can iterate over the DataFrame\n",
    "for rowi, row in train_df.iterrows():\n",
    "    print('row number:', rowi)\n",
    "    print('label:', row['label'])\n",
    "    print('text:', row['text'][:100])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can add a new column by just assigning one.\n",
    "# E.g., here we add a column indicating the character length of each document.\n",
    "train_df['length'] = [len(d) for d in train_df.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Here's another movie that should be loaded into a satellite, fired into space and pointed in the...</td>\n",
       "      <td>4179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>Cuban Blood is one of those sleeper films that has a lot to say about life in a very traditional...</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>This is not \"so bad that it is good,\" it is purely good! For those who don't understand why, you...</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Both visually and musically stunning. A treat for both the eye and the ear. The quintessential V...</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "      <td>'Cry Freedom' is a movie about how far people will go to find the truth.&lt;br /&gt;&lt;br /&gt;The first ha...</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>neg</td>\n",
       "      <td>This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>neg</td>\n",
       "      <td>...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>neg</td>\n",
       "      <td>This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>neg</td>\n",
       "      <td>I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...</td>\n",
       "      <td>2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>neg</td>\n",
       "      <td>Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  \\\n",
       "0     pos   \n",
       "1     pos   \n",
       "2     pos   \n",
       "3     pos   \n",
       "4     pos   \n",
       "..    ...   \n",
       "395   neg   \n",
       "396   neg   \n",
       "397   neg   \n",
       "398   neg   \n",
       "399   neg   \n",
       "\n",
       "                                                                                                    text  \\\n",
       "0    Here's another movie that should be loaded into a satellite, fired into space and pointed in the...   \n",
       "1    Cuban Blood is one of those sleeper films that has a lot to say about life in a very traditional...   \n",
       "2    This is not \"so bad that it is good,\" it is purely good! For those who don't understand why, you...   \n",
       "3    Both visually and musically stunning. A treat for both the eye and the ear. The quintessential V...   \n",
       "4    'Cry Freedom' is a movie about how far people will go to find the truth.<br /><br />The first ha...   \n",
       "..                                                                                                   ...   \n",
       "395  This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...   \n",
       "396  ...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...   \n",
       "397  This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...   \n",
       "398  I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...   \n",
       "399  Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...   \n",
       "\n",
       "     length  \n",
       "0      4179  \n",
       "1       886  \n",
       "2       810  \n",
       "3       749  \n",
       "4       586  \n",
       "..      ...  \n",
       "395     692  \n",
       "396    1560  \n",
       "397     660  \n",
       "398    2859  \n",
       "399     705  \n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas has a pretty rich query language we can use to select rows. e.g.:\n",
    "train_df[train_df.length > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>neg</td>\n",
       "      <td>I feel totally ripped off. Someone needs to refund the $4.95 I spent at Blockbuster to rent this...</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>neg</td>\n",
       "      <td>I made a special effort to see this movie and was totally disappointed with the outcome. On pape...</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>neg</td>\n",
       "      <td>Following the success of \"Paris, Je T'Aime\", a group of directors decided to get together and ma...</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>neg</td>\n",
       "      <td>Tony Goldwyn is a good actor who evidently is trying his hand at directing. \"A Walk on the Moon\"...</td>\n",
       "      <td>2480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>neg</td>\n",
       "      <td>I am stunned to discover the amount of fans this show has. Haven't said that Friends was, at bes...</td>\n",
       "      <td>1670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>neg</td>\n",
       "      <td>This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>neg</td>\n",
       "      <td>...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>neg</td>\n",
       "      <td>This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>neg</td>\n",
       "      <td>I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...</td>\n",
       "      <td>2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>neg</td>\n",
       "      <td>Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  \\\n",
       "200   neg   \n",
       "201   neg   \n",
       "202   neg   \n",
       "203   neg   \n",
       "204   neg   \n",
       "..    ...   \n",
       "395   neg   \n",
       "396   neg   \n",
       "397   neg   \n",
       "398   neg   \n",
       "399   neg   \n",
       "\n",
       "                                                                                                    text  \\\n",
       "200  I feel totally ripped off. Someone needs to refund the $4.95 I spent at Blockbuster to rent this...   \n",
       "201  I made a special effort to see this movie and was totally disappointed with the outcome. On pape...   \n",
       "202  Following the success of \"Paris, Je T'Aime\", a group of directors decided to get together and ma...   \n",
       "203  Tony Goldwyn is a good actor who evidently is trying his hand at directing. \"A Walk on the Moon\"...   \n",
       "204  I am stunned to discover the amount of fans this show has. Haven't said that Friends was, at bes...   \n",
       "..                                                                                                   ...   \n",
       "395  This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...   \n",
       "396  ...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...   \n",
       "397  This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...   \n",
       "398  I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...   \n",
       "399  Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...   \n",
       "\n",
       "     length  \n",
       "200     658  \n",
       "201     892  \n",
       "202    1915  \n",
       "203    2480  \n",
       "204    1670  \n",
       "..      ...  \n",
       "395     692  \n",
       "396    1560  \n",
       "397     660  \n",
       "398    2859  \n",
       "399     705  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[(train_df.length>100) & (train_df.label=='neg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas supports [matplotlib](https://matplotlib.org/3.3.3/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py) for plotting. E.g., here we plot a histogram of document lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "train_df.length.plot.hist(bins=50)\n",
    "plt.xlabel('length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does document length vary by label? Let's plot and see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "train_df[train_df.label=='pos'].length.plot.hist(bins=50, label='pos', alpha=.5)\n",
    "train_df[train_df.label=='neg'].length.plot.hist(bins=50, label='neg', alpha=.5)\n",
    "plt.legend()\n",
    "plt.xlabel('length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm...maybe. It does seem like very short documents are more likely to be positive than negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9cab9ff0823242d77c86d332cc63f3d7",
     "grade": false,
     "grade_id": "cell-c07b51a18a2af4ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Featurization\n",
    "\n",
    "As we discussed in class, a first step in text classification is converting a document into a **feature vector**.\n",
    "\n",
    "There are many things we can consider:\n",
    "\n",
    "- Do we store word counts or just binary values (1 if word is present, 0 otherwise)?\n",
    "- Do we keep punctuation?\n",
    "- Do we keep capitalization?\n",
    "- Do we just use words or also phrases?\n",
    "\n",
    "There's no \"best\" answer to these questions. It is a tradeoff in the number of unique tokens in our model as well as the frequency with which we see each token in the training data. This will affect things like over/under fitting.\n",
    "\n",
    "Below, complete the `tokenize` function, which takes as input a string representing a document, and returns a list of strings representing each token in the document. Part of your solution will use the `.split()` function of string objects. Then, we have two boolean flags:\n",
    "\n",
    "- `ignore_case`: if True, convert the entire string to lowercase.\n",
    "- `strip_punct`: if True, remove any leading or trailing punctuation for each token. E.g., \"!it's?\" would become \"it's\". You can use Python's [regular expression library](https://docs.python.org/3/library/re.html) library to do so. Hint: consider using the `sub` method combined with the `\\w` and `\\W` word classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55b53512ab22f019f6d610e6511ebc79",
     "grade": false,
     "grade_id": "tokenize",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(document, strip_punct=True, ignore_case=True):\n",
    "    # YOUR CODE HERE   \n",
    "    \n",
    "    token=document.split()\n",
    "    if ignore_case==True:\n",
    "        token_l=[x.lower() for x in token]  \n",
    "        token=token_l\n",
    "    #print(token_l)\n",
    "    if strip_punct==True:\n",
    "        #token_s=[re.sub(r'[^\\w\\s]', '', x) for x in token_l]\n",
    "        #token_s=[x.strip(string.punctuation) for x in token]\n",
    "          token_s=[re.sub('\\S+', lambda m: re.sub('^\\W+|\\W+$', '', m.group()), x) for x in token]\n",
    "          token=token_s\n",
    "    #print (token)\n",
    "    return token\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3d62d3bb726ebada3f3bea74b461aa1",
     "grade": true,
     "grade_id": "tokenize-test",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert tokenize(\" Hi there! Isn't this fun?\", strip_punct=True, ignore_case=True) == ['hi', 'there', \"isn't\", 'this', 'fun']\n",
    "assert tokenize(\" Hi there! Isn't this fun?\", strip_punct=False, ignore_case=True) == ['hi', 'there!', \"isn't\", 'this', 'fun?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6ddf5ec38135d74502cfa91d60c07b1",
     "grade": false,
     "grade_id": "cell-ffe48966997b3a33",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, we can choose a specific tokenization setting and apply it to all documents.\n",
    "\n",
    "We'll store the results in a new column called `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Here's another movie that should be loaded into a satellite, fired into space and pointed in the...</td>\n",
       "      <td>4179</td>\n",
       "      <td>[here's, another, movie, that, should, be, loaded, into, a, satellite, fired, into, space, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>Cuban Blood is one of those sleeper films that has a lot to say about life in a very traditional...</td>\n",
       "      <td>886</td>\n",
       "      <td>[cuban, blood, is, one, of, those, sleeper, films, that, has, a, lot, to, say, about, life, in, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>This is not \"so bad that it is good,\" it is purely good! For those who don't understand why, you...</td>\n",
       "      <td>810</td>\n",
       "      <td>[this, is, not, so, bad, that, it, is, good, it, is, purely, good, for, those, who, don't, under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Both visually and musically stunning. A treat for both the eye and the ear. The quintessential V...</td>\n",
       "      <td>749</td>\n",
       "      <td>[both, visually, and, musically, stunning, a, treat, for, both, the, eye, and, the, ear, the, qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "      <td>'Cry Freedom' is a movie about how far people will go to find the truth.&lt;br /&gt;&lt;br /&gt;The first ha...</td>\n",
       "      <td>586</td>\n",
       "      <td>[cry, freedom, is, a, movie, about, how, far, people, will, go, to, find, the, truth.&lt;br, br, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>neg</td>\n",
       "      <td>This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...</td>\n",
       "      <td>692</td>\n",
       "      <td>[this, movie, was, the, most, out, of, line, and, liberally, fed, movie, i, have, ever, seen, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>neg</td>\n",
       "      <td>...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...</td>\n",
       "      <td>1560</td>\n",
       "      <td>[you, know, the, rest, if, you, want, a, good, zombie, movie, don't, rent, this, movie, if, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>neg</td>\n",
       "      <td>This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...</td>\n",
       "      <td>660</td>\n",
       "      <td>[this, was, longer, than, the, ten, commandments, all, lord, of, the, rings, and, the, matrix, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>neg</td>\n",
       "      <td>I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...</td>\n",
       "      <td>2859</td>\n",
       "      <td>[i, watched, scarecrows, because, of, the, buzz, surrounding, it, well, i, can't, imagine, anyon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>neg</td>\n",
       "      <td>Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...</td>\n",
       "      <td>705</td>\n",
       "      <td>[trifling, romantic, drama, directed, by, clint, eastwood, about, the, loving, relationship, whi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  \\\n",
       "0     pos   \n",
       "1     pos   \n",
       "2     pos   \n",
       "3     pos   \n",
       "4     pos   \n",
       "..    ...   \n",
       "395   neg   \n",
       "396   neg   \n",
       "397   neg   \n",
       "398   neg   \n",
       "399   neg   \n",
       "\n",
       "                                                                                                    text  \\\n",
       "0    Here's another movie that should be loaded into a satellite, fired into space and pointed in the...   \n",
       "1    Cuban Blood is one of those sleeper films that has a lot to say about life in a very traditional...   \n",
       "2    This is not \"so bad that it is good,\" it is purely good! For those who don't understand why, you...   \n",
       "3    Both visually and musically stunning. A treat for both the eye and the ear. The quintessential V...   \n",
       "4    'Cry Freedom' is a movie about how far people will go to find the truth.<br /><br />The first ha...   \n",
       "..                                                                                                   ...   \n",
       "395  This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...   \n",
       "396  ...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...   \n",
       "397  This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...   \n",
       "398  I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...   \n",
       "399  Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...   \n",
       "\n",
       "     length  \\\n",
       "0      4179   \n",
       "1       886   \n",
       "2       810   \n",
       "3       749   \n",
       "4       586   \n",
       "..      ...   \n",
       "395     692   \n",
       "396    1560   \n",
       "397     660   \n",
       "398    2859   \n",
       "399     705   \n",
       "\n",
       "                                                                                                  tokens  \n",
       "0    [here's, another, movie, that, should, be, loaded, into, a, satellite, fired, into, space, and, ...  \n",
       "1    [cuban, blood, is, one, of, those, sleeper, films, that, has, a, lot, to, say, about, life, in, ...  \n",
       "2    [this, is, not, so, bad, that, it, is, good, it, is, purely, good, for, those, who, don't, under...  \n",
       "3    [both, visually, and, musically, stunning, a, treat, for, both, the, eye, and, the, ear, the, qu...  \n",
       "4    [cry, freedom, is, a, movie, about, how, far, people, will, go, to, find, the, truth.<br, br, th...  \n",
       "..                                                                                                   ...  \n",
       "395  [this, movie, was, the, most, out, of, line, and, liberally, fed, movie, i, have, ever, seen, in...  \n",
       "396  [you, know, the, rest, if, you, want, a, good, zombie, movie, don't, rent, this, movie, if, you,...  \n",
       "397  [this, was, longer, than, the, ten, commandments, all, lord, of, the, rings, and, the, matrix, t...  \n",
       "398  [i, watched, scarecrows, because, of, the, buzz, surrounding, it, well, i, can't, imagine, anyon...  \n",
       "399  [trifling, romantic, drama, directed, by, clint, eastwood, about, the, loving, relationship, whi...  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['tokens'] = [tokenize(d, strip_punct=True, ignore_case=True) for d in train_df.text]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to create a feature vector for each document. For now, we'll assume **binary features**, which means for each document we'll store a `dict` where words are keys and values are 1 for each word that exists in the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5cf6d0825f0856cca6c4f06ca4a5f03",
     "grade": false,
     "grade_id": "featurize",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def featurize(tokens):\n",
    "    # YOUR CODE HERE\n",
    "    feats={}\n",
    "    for x in tokens:\n",
    "        feats[x]=1\n",
    "    return feats\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a33b71afaa65c05d1c0c54ae305200dc",
     "grade": true,
     "grade_id": "featurize-test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hi': 1, 'there': 1, \"isn't\": 1, 'this': 1, 'fun': 1}\n"
     ]
    }
   ],
   "source": [
    "feats = featurize(tokenize(\" Hi there! Isn't this fun? Hi there\", strip_punct=True, ignore_case=True))\n",
    "print(feats)\n",
    "assert sorted(feats.items()) == [('fun', 1), ('hi', 1), (\"isn't\", 1), ('there', 1), ('this', 1)]\n",
    "# note that sets and dicts are unordered; i'm sorting by alpha for testing purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can featurize all the documents and assign to a new column called `raw_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>raw_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Here's another movie that should be loaded into a satellite, fired into space and pointed in the...</td>\n",
       "      <td>4179</td>\n",
       "      <td>[here's, another, movie, that, should, be, loaded, into, a, satellite, fired, into, space, and, ...</td>\n",
       "      <td>{'here's': 1, 'another': 1, 'movie': 1, 'that': 1, 'should': 1, 'be': 1, 'loaded': 1, 'into': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>Cuban Blood is one of those sleeper films that has a lot to say about life in a very traditional...</td>\n",
       "      <td>886</td>\n",
       "      <td>[cuban, blood, is, one, of, those, sleeper, films, that, has, a, lot, to, say, about, life, in, ...</td>\n",
       "      <td>{'cuban': 1, 'blood': 1, 'is': 1, 'one': 1, 'of': 1, 'those': 1, 'sleeper': 1, 'films': 1, 'that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>This is not \"so bad that it is good,\" it is purely good! For those who don't understand why, you...</td>\n",
       "      <td>810</td>\n",
       "      <td>[this, is, not, so, bad, that, it, is, good, it, is, purely, good, for, those, who, don't, under...</td>\n",
       "      <td>{'this': 1, 'is': 1, 'not': 1, 'so': 1, 'bad': 1, 'that': 1, 'it': 1, 'good': 1, 'purely': 1, 'f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Both visually and musically stunning. A treat for both the eye and the ear. The quintessential V...</td>\n",
       "      <td>749</td>\n",
       "      <td>[both, visually, and, musically, stunning, a, treat, for, both, the, eye, and, the, ear, the, qu...</td>\n",
       "      <td>{'both': 1, 'visually': 1, 'and': 1, 'musically': 1, 'stunning': 1, 'a': 1, 'treat': 1, 'for': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "      <td>'Cry Freedom' is a movie about how far people will go to find the truth.&lt;br /&gt;&lt;br /&gt;The first ha...</td>\n",
       "      <td>586</td>\n",
       "      <td>[cry, freedom, is, a, movie, about, how, far, people, will, go, to, find, the, truth.&lt;br, br, th...</td>\n",
       "      <td>{'cry': 1, 'freedom': 1, 'is': 1, 'a': 1, 'movie': 1, 'about': 1, 'how': 1, 'far': 1, 'people': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>neg</td>\n",
       "      <td>This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...</td>\n",
       "      <td>692</td>\n",
       "      <td>[this, movie, was, the, most, out, of, line, and, liberally, fed, movie, i, have, ever, seen, in...</td>\n",
       "      <td>{'this': 1, 'movie': 1, 'was': 1, 'the': 1, 'most': 1, 'out': 1, 'of': 1, 'line': 1, 'and': 1, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>neg</td>\n",
       "      <td>...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...</td>\n",
       "      <td>1560</td>\n",
       "      <td>[you, know, the, rest, if, you, want, a, good, zombie, movie, don't, rent, this, movie, if, you,...</td>\n",
       "      <td>{'you': 1, 'know': 1, 'the': 1, 'rest': 1, 'if': 1, 'want': 1, 'a': 1, 'good': 1, 'zombie': 1, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>neg</td>\n",
       "      <td>This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...</td>\n",
       "      <td>660</td>\n",
       "      <td>[this, was, longer, than, the, ten, commandments, all, lord, of, the, rings, and, the, matrix, t...</td>\n",
       "      <td>{'this': 1, 'was': 1, 'longer': 1, 'than': 1, 'the': 1, 'ten': 1, 'commandments': 1, 'all': 1, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>neg</td>\n",
       "      <td>I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...</td>\n",
       "      <td>2859</td>\n",
       "      <td>[i, watched, scarecrows, because, of, the, buzz, surrounding, it, well, i, can't, imagine, anyon...</td>\n",
       "      <td>{'i': 1, 'watched': 1, 'scarecrows': 1, 'because': 1, 'of': 1, 'the': 1, 'buzz': 1, 'surrounding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>neg</td>\n",
       "      <td>Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...</td>\n",
       "      <td>705</td>\n",
       "      <td>[trifling, romantic, drama, directed, by, clint, eastwood, about, the, loving, relationship, whi...</td>\n",
       "      <td>{'trifling': 1, 'romantic': 1, 'drama': 1, 'directed': 1, 'by': 1, 'clint': 1, 'eastwood': 1, 'a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  \\\n",
       "0     pos   \n",
       "1     pos   \n",
       "2     pos   \n",
       "3     pos   \n",
       "4     pos   \n",
       "..    ...   \n",
       "395   neg   \n",
       "396   neg   \n",
       "397   neg   \n",
       "398   neg   \n",
       "399   neg   \n",
       "\n",
       "                                                                                                    text  \\\n",
       "0    Here's another movie that should be loaded into a satellite, fired into space and pointed in the...   \n",
       "1    Cuban Blood is one of those sleeper films that has a lot to say about life in a very traditional...   \n",
       "2    This is not \"so bad that it is good,\" it is purely good! For those who don't understand why, you...   \n",
       "3    Both visually and musically stunning. A treat for both the eye and the ear. The quintessential V...   \n",
       "4    'Cry Freedom' is a movie about how far people will go to find the truth.<br /><br />The first ha...   \n",
       "..                                                                                                   ...   \n",
       "395  This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...   \n",
       "396  ...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...   \n",
       "397  This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...   \n",
       "398  I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...   \n",
       "399  Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...   \n",
       "\n",
       "     length  \\\n",
       "0      4179   \n",
       "1       886   \n",
       "2       810   \n",
       "3       749   \n",
       "4       586   \n",
       "..      ...   \n",
       "395     692   \n",
       "396    1560   \n",
       "397     660   \n",
       "398    2859   \n",
       "399     705   \n",
       "\n",
       "                                                                                                  tokens  \\\n",
       "0    [here's, another, movie, that, should, be, loaded, into, a, satellite, fired, into, space, and, ...   \n",
       "1    [cuban, blood, is, one, of, those, sleeper, films, that, has, a, lot, to, say, about, life, in, ...   \n",
       "2    [this, is, not, so, bad, that, it, is, good, it, is, purely, good, for, those, who, don't, under...   \n",
       "3    [both, visually, and, musically, stunning, a, treat, for, both, the, eye, and, the, ear, the, qu...   \n",
       "4    [cry, freedom, is, a, movie, about, how, far, people, will, go, to, find, the, truth.<br, br, th...   \n",
       "..                                                                                                   ...   \n",
       "395  [this, movie, was, the, most, out, of, line, and, liberally, fed, movie, i, have, ever, seen, in...   \n",
       "396  [you, know, the, rest, if, you, want, a, good, zombie, movie, don't, rent, this, movie, if, you,...   \n",
       "397  [this, was, longer, than, the, ten, commandments, all, lord, of, the, rings, and, the, matrix, t...   \n",
       "398  [i, watched, scarecrows, because, of, the, buzz, surrounding, it, well, i, can't, imagine, anyon...   \n",
       "399  [trifling, romantic, drama, directed, by, clint, eastwood, about, the, loving, relationship, whi...   \n",
       "\n",
       "                                                                                            raw_features  \n",
       "0    {'here's': 1, 'another': 1, 'movie': 1, 'that': 1, 'should': 1, 'be': 1, 'loaded': 1, 'into': 1,...  \n",
       "1    {'cuban': 1, 'blood': 1, 'is': 1, 'one': 1, 'of': 1, 'those': 1, 'sleeper': 1, 'films': 1, 'that...  \n",
       "2    {'this': 1, 'is': 1, 'not': 1, 'so': 1, 'bad': 1, 'that': 1, 'it': 1, 'good': 1, 'purely': 1, 'f...  \n",
       "3    {'both': 1, 'visually': 1, 'and': 1, 'musically': 1, 'stunning': 1, 'a': 1, 'treat': 1, 'for': 1...  \n",
       "4    {'cry': 1, 'freedom': 1, 'is': 1, 'a': 1, 'movie': 1, 'about': 1, 'how': 1, 'far': 1, 'people': ...  \n",
       "..                                                                                                   ...  \n",
       "395  {'this': 1, 'movie': 1, 'was': 1, 'the': 1, 'most': 1, 'out': 1, 'of': 1, 'line': 1, 'and': 1, '...  \n",
       "396  {'you': 1, 'know': 1, 'the': 1, 'rest': 1, 'if': 1, 'want': 1, 'a': 1, 'good': 1, 'zombie': 1, '...  \n",
       "397  {'this': 1, 'was': 1, 'longer': 1, 'than': 1, 'the': 1, 'ten': 1, 'commandments': 1, 'all': 1, '...  \n",
       "398  {'i': 1, 'watched': 1, 'scarecrows': 1, 'because': 1, 'of': 1, 'the': 1, 'buzz': 1, 'surrounding...  \n",
       "399  {'trifling': 1, 'romantic': 1, 'drama': 1, 'directed': 1, 'by': 1, 'clint': 1, 'eastwood': 1, 'a...  \n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['raw_features'] = [featurize(t) for t in train_df.tokens]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common issue in text classification is that many words occur infrequently. This poses a challenge to any machine learning method -- if we've only seen a word once, we cannot be very confident about whether it correlates with the positive or negative class! First, let's count word frequencies by completing the method below. It takes in a list of `dict` objects, from the `raw_features` column, and returns a [`Counter`](https://docs.python.org/3/library/collections.html#collections.Counter) object representing the number of documents each word appears in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78abc6a7187f2e960ba6f3952db2ae1a",
     "grade": false,
     "grade_id": "count-words",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def count_word_document_frequency(dict_list):\n",
    "    # YOUR CODE HERE\n",
    "    count={}\n",
    "    for x in dict_list:\n",
    "            words=x.keys()\n",
    "            for word in words:\n",
    "                if word in count:\n",
    "                        count[word] = count[word] + 1\n",
    "                else:\n",
    "                        count[word] = 1\n",
    "    return Counter(count)              \n",
    "    raise NotImplementedError()\n",
    "word_counts = count_word_document_frequency(train_df.raw_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12166"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we should have 12,166 unique words\n",
    "len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 399),\n",
       " ('and', 392),\n",
       " ('a', 391),\n",
       " ('to', 380),\n",
       " ('of', 376),\n",
       " ('this', 364),\n",
       " ('is', 355),\n",
       " ('in', 350),\n",
       " ('it', 343),\n",
       " ('that', 327)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can print the most common entries in a Counter like so:\n",
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6a8c634c46533ff04bd69cb90c15e1e",
     "grade": true,
     "grade_id": "count-words-test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert count_word_document_frequency(train_df.raw_features).most_common(5) == [('the', 399), ('and', 392), ('a', 391), ('to', 380), ('of', 376)]\n",
    "\n",
    "assert len(count_word_document_frequency(train_df.raw_features)) == 12166"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just how common are rare words? Let's plot a histogram to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(1, 7571), (2, 1698), (3, 804), (4, 438), (5, 268)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(word_counts.values(), bins=100)\n",
    "plt.xlabel('number of documents a word appears in')\n",
    "plt.ylabel('number of words')\n",
    "plt.show()\n",
    "Counter(word_counts.values()).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Whoa!** There are 7,571 out of 12,166 words that occur exactly once, and 1,698 that occur exactly twice.\n",
    "\n",
    "This is very common in text collections. There are very many rare words and a small number of very common terms. This can sometimes be better seen in a `log-log` plot. These data somewhat follow something known as a [Power Law](https://en.wikipedia.org/wiki/Power_law) distribution, which just means this log-log plot is well-approximated by a linear fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log-log plot of word frequencies\n",
    "def log_log_plot(word_counts):\n",
    "    plt.figure()\n",
    "    plt.loglog(sorted(word_counts.values())[::-1])\n",
    "    plt.xlabel('word rank')\n",
    "    plt.ylabel('number of documents a word appears in')\n",
    "    plt.show()\n",
    "    \n",
    "log_log_plot(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That long, horizontal segment at the bottom right of the plot represents the 7,571 words that occur exactly once.\n",
    "\n",
    "The words at the top left are the most common words (`the`, `and`, etc.)\n",
    "\n",
    "It seems that neither very common nor very rare words should be informative in our model.\n",
    "- For very rare words, we don't see enough examples to have much confidence in our probability estimates.\n",
    "- For very common words, if they appear in just about every document, they probably do not correlate with the class label.\n",
    "\n",
    "We will next create a `vocabulary`, which contains our final set of unique features. To do so, we will remove terms that occur too frequently or too infrequently.\n",
    "\n",
    "The inputs to `create_vocabulary` are:\n",
    "- word_counts: the Counter object compute above\n",
    "- min_count: minimum document count allowed\n",
    "- max_count: maximum document count allowed\n",
    "\n",
    "This function should return a `dict` where each key is a word and the value is a unique `int` representing the identifier for that word. We will assign each word its value in alphabetical order, e.g. `{'aardvark': 0, 'beetle': 1, ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "543ee07eac232b58cb4fa22ecc8e780f",
     "grade": false,
     "grade_id": "prune-words",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 0),\n",
       " ('1', 1),\n",
       " ('1/2', 2),\n",
       " ('10', 3),\n",
       " ('10/10', 4),\n",
       " ('100', 5),\n",
       " ('11', 6),\n",
       " ('12', 7),\n",
       " ('15', 8),\n",
       " ('16', 9)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_vocabulary(word_counts, min_count=2, max_count=100):\n",
    "    # YOUR CODE HERE\n",
    "    limit_counts=Counter(i for i in word_counts.elements() if word_counts[i]>=min_count and word_counts[i]<=max_count )\n",
    "    #print(limit_counts)\n",
    "    temp=dict(limit_counts)\n",
    "    vocabulary_sort=dict(sorted(temp.items()))\n",
    "    value=0\n",
    "    vocabulary=dict()\n",
    "    for key in vocabulary_sort:\n",
    "        vocabulary[key]=value\n",
    "        value+=1\n",
    "    return vocabulary\n",
    "    \n",
    "    word_sort=sorted(word_counts)\n",
    "    raise NotImplementedError()\n",
    "\n",
    "vocabulary = create_vocabulary(word_counts, min_count=2, max_count=100)\n",
    "list(vocabulary.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27b99c08b728700a04e0828dd29da78f",
     "grade": true,
     "grade_id": "prune-words-test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(vocabulary) == 4519\n",
    "assert list(vocabulary.items())[:10] == [('0', 0), ('1', 1), ('1/2', 2), ('10', 3), ('10/10', 4), ('100', 5), ('11', 6), ('12', 7), ('15', 8), ('16', 9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've finalized our vocabulary, we need to go back through all our `raw_features` in `train_df` and remove any that are not in this `vocabulary`. We store the result in a new column called `features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>raw_features</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Here's another movie that should be loaded into a satellite, fired into space and pointed in the...</td>\n",
       "      <td>4179</td>\n",
       "      <td>[here's, another, movie, that, should, be, loaded, into, a, satellite, fired, into, space, and, ...</td>\n",
       "      <td>{'here's': 1, 'another': 1, 'movie': 1, 'that': 1, 'should': 1, 'be': 1, 'loaded': 1, 'into': 1,...</td>\n",
       "      <td>{'here's': 1, 'another': 1, 'should': 1, 'into': 1, 'fired': 1, 'space': 1, 'pointed': 1, 'direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>Cuban Blood is one of those sleeper films that has a lot to say about life in a very traditional...</td>\n",
       "      <td>886</td>\n",
       "      <td>[cuban, blood, is, one, of, those, sleeper, films, that, has, a, lot, to, say, about, life, in, ...</td>\n",
       "      <td>{'cuban': 1, 'blood': 1, 'is': 1, 'one': 1, 'of': 1, 'those': 1, 'sleeper': 1, 'films': 1, 'that...</td>\n",
       "      <td>{'cuban': 1, 'blood': 1, 'those': 1, 'films': 1, 'lot': 1, 'say': 1, 'life': 1, 'traditional': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>This is not \"so bad that it is good,\" it is purely good! For those who don't understand why, you...</td>\n",
       "      <td>810</td>\n",
       "      <td>[this, is, not, so, bad, that, it, is, good, it, is, purely, good, for, those, who, don't, under...</td>\n",
       "      <td>{'this': 1, 'is': 1, 'not': 1, 'so': 1, 'bad': 1, 'that': 1, 'it': 1, 'good': 1, 'purely': 1, 'f...</td>\n",
       "      <td>{'bad': 1, 'purely': 1, 'those': 1, 'don't': 1, 'understand': 1, 'why': 1, 'four': 1, 'year': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Both visually and musically stunning. A treat for both the eye and the ear. The quintessential V...</td>\n",
       "      <td>749</td>\n",
       "      <td>[both, visually, and, musically, stunning, a, treat, for, both, the, eye, and, the, ear, the, qu...</td>\n",
       "      <td>{'both': 1, 'visually': 1, 'and': 1, 'musically': 1, 'stunning': 1, 'a': 1, 'treat': 1, 'for': 1...</td>\n",
       "      <td>{'both': 1, 'visually': 1, 'stunning': 1, 'treat': 1, 'eye': 1, 'ear': 1, 'quintessential': 1, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "      <td>'Cry Freedom' is a movie about how far people will go to find the truth.&lt;br /&gt;&lt;br /&gt;The first ha...</td>\n",
       "      <td>586</td>\n",
       "      <td>[cry, freedom, is, a, movie, about, how, far, people, will, go, to, find, the, truth.&lt;br, br, th...</td>\n",
       "      <td>{'cry': 1, 'freedom': 1, 'is': 1, 'a': 1, 'movie': 1, 'about': 1, 'how': 1, 'far': 1, 'people': ...</td>\n",
       "      <td>{'cry': 1, 'freedom': 1, 'how': 1, 'far': 1, 'people': 1, 'go': 1, 'find': 1, 'half': 1, 'intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>neg</td>\n",
       "      <td>This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...</td>\n",
       "      <td>692</td>\n",
       "      <td>[this, movie, was, the, most, out, of, line, and, liberally, fed, movie, i, have, ever, seen, in...</td>\n",
       "      <td>{'this': 1, 'movie': 1, 'was': 1, 'the': 1, 'most': 1, 'out': 1, 'of': 1, 'line': 1, 'and': 1, '...</td>\n",
       "      <td>{'most': 1, 'line': 1, 'fed': 1, 'ever': 1, 'seen': 1, 'life': 1, 'besides': 1, 'information': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>neg</td>\n",
       "      <td>...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...</td>\n",
       "      <td>1560</td>\n",
       "      <td>[you, know, the, rest, if, you, want, a, good, zombie, movie, don't, rent, this, movie, if, you,...</td>\n",
       "      <td>{'you': 1, 'know': 1, 'the': 1, 'rest': 1, 'if': 1, 'want': 1, 'a': 1, 'good': 1, 'zombie': 1, '...</td>\n",
       "      <td>{'know': 1, 'rest': 1, 'want': 1, 'zombie': 1, 'don't': 1, 'rent': 1, 'look': 1, 'hood': 1, 'lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>neg</td>\n",
       "      <td>This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...</td>\n",
       "      <td>660</td>\n",
       "      <td>[this, was, longer, than, the, ten, commandments, all, lord, of, the, rings, and, the, matrix, t...</td>\n",
       "      <td>{'this': 1, 'was': 1, 'longer': 1, 'than': 1, 'the': 1, 'ten': 1, 'commandments': 1, 'all': 1, '...</td>\n",
       "      <td>{'longer': 1, 'ten': 1, 'matrix': 1, 'trilogy': 1, 'combined': 1, 'oh': 1, 'nightmare': 1, 'sing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>neg</td>\n",
       "      <td>I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...</td>\n",
       "      <td>2859</td>\n",
       "      <td>[i, watched, scarecrows, because, of, the, buzz, surrounding, it, well, i, can't, imagine, anyon...</td>\n",
       "      <td>{'i': 1, 'watched': 1, 'scarecrows': 1, 'because': 1, 'of': 1, 'the': 1, 'buzz': 1, 'surrounding...</td>\n",
       "      <td>{'watched': 1, 'because': 1, 'surrounding': 1, 'well': 1, 'can't': 1, 'imagine': 1, 'anyone': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>neg</td>\n",
       "      <td>Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...</td>\n",
       "      <td>705</td>\n",
       "      <td>[trifling, romantic, drama, directed, by, clint, eastwood, about, the, loving, relationship, whi...</td>\n",
       "      <td>{'trifling': 1, 'romantic': 1, 'drama': 1, 'directed': 1, 'by': 1, 'clint': 1, 'eastwood': 1, 'a...</td>\n",
       "      <td>{'trifling': 1, 'romantic': 1, 'drama': 1, 'directed': 1, 'clint': 1, 'loving': 1, 'relationship...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  \\\n",
       "0     pos   \n",
       "1     pos   \n",
       "2     pos   \n",
       "3     pos   \n",
       "4     pos   \n",
       "..    ...   \n",
       "395   neg   \n",
       "396   neg   \n",
       "397   neg   \n",
       "398   neg   \n",
       "399   neg   \n",
       "\n",
       "                                                                                                    text  \\\n",
       "0    Here's another movie that should be loaded into a satellite, fired into space and pointed in the...   \n",
       "1    Cuban Blood is one of those sleeper films that has a lot to say about life in a very traditional...   \n",
       "2    This is not \"so bad that it is good,\" it is purely good! For those who don't understand why, you...   \n",
       "3    Both visually and musically stunning. A treat for both the eye and the ear. The quintessential V...   \n",
       "4    'Cry Freedom' is a movie about how far people will go to find the truth.<br /><br />The first ha...   \n",
       "..                                                                                                   ...   \n",
       "395  This movie was the most out of line and liberally fed movie i have ever seen in my life. (Beside...   \n",
       "396  ...you know the rest. If you want a good zombie movie, DON'T RENT THIS MOVIE. If you want a docu...   \n",
       "397  This was longer than the Ten Commandments, All Lord of the Rings and the Matrix Trilogy combined...   \n",
       "398  I watched SCARECROWS because of the buzz surrounding it. Well, I can't imagine anyone liking thi...   \n",
       "399  Trifling romantic drama directed by Clint Eastwood about the loving relationship which grows bet...   \n",
       "\n",
       "     length  \\\n",
       "0      4179   \n",
       "1       886   \n",
       "2       810   \n",
       "3       749   \n",
       "4       586   \n",
       "..      ...   \n",
       "395     692   \n",
       "396    1560   \n",
       "397     660   \n",
       "398    2859   \n",
       "399     705   \n",
       "\n",
       "                                                                                                  tokens  \\\n",
       "0    [here's, another, movie, that, should, be, loaded, into, a, satellite, fired, into, space, and, ...   \n",
       "1    [cuban, blood, is, one, of, those, sleeper, films, that, has, a, lot, to, say, about, life, in, ...   \n",
       "2    [this, is, not, so, bad, that, it, is, good, it, is, purely, good, for, those, who, don't, under...   \n",
       "3    [both, visually, and, musically, stunning, a, treat, for, both, the, eye, and, the, ear, the, qu...   \n",
       "4    [cry, freedom, is, a, movie, about, how, far, people, will, go, to, find, the, truth.<br, br, th...   \n",
       "..                                                                                                   ...   \n",
       "395  [this, movie, was, the, most, out, of, line, and, liberally, fed, movie, i, have, ever, seen, in...   \n",
       "396  [you, know, the, rest, if, you, want, a, good, zombie, movie, don't, rent, this, movie, if, you,...   \n",
       "397  [this, was, longer, than, the, ten, commandments, all, lord, of, the, rings, and, the, matrix, t...   \n",
       "398  [i, watched, scarecrows, because, of, the, buzz, surrounding, it, well, i, can't, imagine, anyon...   \n",
       "399  [trifling, romantic, drama, directed, by, clint, eastwood, about, the, loving, relationship, whi...   \n",
       "\n",
       "                                                                                            raw_features  \\\n",
       "0    {'here's': 1, 'another': 1, 'movie': 1, 'that': 1, 'should': 1, 'be': 1, 'loaded': 1, 'into': 1,...   \n",
       "1    {'cuban': 1, 'blood': 1, 'is': 1, 'one': 1, 'of': 1, 'those': 1, 'sleeper': 1, 'films': 1, 'that...   \n",
       "2    {'this': 1, 'is': 1, 'not': 1, 'so': 1, 'bad': 1, 'that': 1, 'it': 1, 'good': 1, 'purely': 1, 'f...   \n",
       "3    {'both': 1, 'visually': 1, 'and': 1, 'musically': 1, 'stunning': 1, 'a': 1, 'treat': 1, 'for': 1...   \n",
       "4    {'cry': 1, 'freedom': 1, 'is': 1, 'a': 1, 'movie': 1, 'about': 1, 'how': 1, 'far': 1, 'people': ...   \n",
       "..                                                                                                   ...   \n",
       "395  {'this': 1, 'movie': 1, 'was': 1, 'the': 1, 'most': 1, 'out': 1, 'of': 1, 'line': 1, 'and': 1, '...   \n",
       "396  {'you': 1, 'know': 1, 'the': 1, 'rest': 1, 'if': 1, 'want': 1, 'a': 1, 'good': 1, 'zombie': 1, '...   \n",
       "397  {'this': 1, 'was': 1, 'longer': 1, 'than': 1, 'the': 1, 'ten': 1, 'commandments': 1, 'all': 1, '...   \n",
       "398  {'i': 1, 'watched': 1, 'scarecrows': 1, 'because': 1, 'of': 1, 'the': 1, 'buzz': 1, 'surrounding...   \n",
       "399  {'trifling': 1, 'romantic': 1, 'drama': 1, 'directed': 1, 'by': 1, 'clint': 1, 'eastwood': 1, 'a...   \n",
       "\n",
       "                                                                                                features  \n",
       "0    {'here's': 1, 'another': 1, 'should': 1, 'into': 1, 'fired': 1, 'space': 1, 'pointed': 1, 'direc...  \n",
       "1    {'cuban': 1, 'blood': 1, 'those': 1, 'films': 1, 'lot': 1, 'say': 1, 'life': 1, 'traditional': 1...  \n",
       "2    {'bad': 1, 'purely': 1, 'those': 1, 'don't': 1, 'understand': 1, 'why': 1, 'four': 1, 'year': 1,...  \n",
       "3    {'both': 1, 'visually': 1, 'stunning': 1, 'treat': 1, 'eye': 1, 'ear': 1, 'quintessential': 1, '...  \n",
       "4    {'cry': 1, 'freedom': 1, 'how': 1, 'far': 1, 'people': 1, 'go': 1, 'find': 1, 'half': 1, 'intere...  \n",
       "..                                                                                                   ...  \n",
       "395  {'most': 1, 'line': 1, 'fed': 1, 'ever': 1, 'seen': 1, 'life': 1, 'besides': 1, 'information': 1...  \n",
       "396  {'know': 1, 'rest': 1, 'want': 1, 'zombie': 1, 'don't': 1, 'rent': 1, 'look': 1, 'hood': 1, 'lif...  \n",
       "397  {'longer': 1, 'ten': 1, 'matrix': 1, 'trilogy': 1, 'combined': 1, 'oh': 1, 'nightmare': 1, 'sing...  \n",
       "398  {'watched': 1, 'because': 1, 'surrounding': 1, 'well': 1, 'can't': 1, 'imagine': 1, 'anyone': 1,...  \n",
       "399  {'trifling': 1, 'romantic': 1, 'drama': 1, 'directed': 1, 'clint': 1, 'loving': 1, 'relationship...  \n",
       "\n",
       "[400 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prune_features(vocabulary, raw_feature_dict):\n",
    "    return {k:v for k,v in raw_feature_dict.items() if k in vocabulary}\n",
    "\n",
    "train_df['features'] = [prune_features(vocabulary, f) for f in train_df.raw_features]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just as a sanity check, let's plot the word frequency distribution again.\n",
    "word_counts_pruned = count_word_document_frequency(train_df.features)\n",
    "log_log_plot(word_counts_pruned)\n",
    "# yes, we've chopped off the left and right part of the original graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "OK, now we're finally ready to fit a classifier. Let's start with Bernoulli Naive Bayes. Recall the formula to compute the word probabilities for each class, using smoothing:\n",
    "\n",
    "$$p(x_{k}=1|y=1) = \\frac{\\epsilon + \\sum_{(x_i, y_i) \\in D}1[x_{ik}=1 \\wedge y_i=1]}{2 \\epsilon + \\sum_{(x_i, y_i) \\in D} 1[y_i=1]}$$\n",
    "\n",
    "Commonly, $\\epsilon=1$ is used (“plus one” smoothing). \n",
    "\n",
    "That is, the probability that word $k$ is present in a positive document is the fraction of positive documents that contain word $k$, modulo the smoothing terms.\n",
    "\n",
    "To compute this, we'll first create a `dict` where keys are words and values are `p(x_{k}=1|y=1)`. We'll create a separate `dict` for $y=$pos and $y=$neg. You should be able to reuse your `count_word_document_frequency` method to help with this.\n",
    "\n",
    "**note**: be sure to account for words that only appear in one class. These would only have value $\\epsilon$ in the numerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1bda08c30b66746834f0cfc3a337fec",
     "grade": false,
     "grade_id": "p_x_given_y",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def p_x_given_y(train_df, vocabulary, label, epsilon):\n",
    "    # YOUR CODE HERE\n",
    "    dict_x_given_y=dict.fromkeys(vocabulary,0)\n",
    "    train_df_p=train_df[train_df['label']==label]\n",
    "    c_x_y=count_word_document_frequency(train_df_p.features)\n",
    "    c_y=len(train_df_p)\n",
    "    for key in vocabulary:\n",
    "        dict_x_given_y[key]=(epsilon+c_x_y[key])/(2*epsilon+c_y)\n",
    "        #print(dict_x_given_y[key])\n",
    "    \n",
    "    return dict_x_given_y\n",
    "\n",
    "    raise NotImplementedError()\n",
    "\n",
    "p_x_given_pos = p_x_given_y(train_df, vocabulary, 'pos', epsilon=1)\n",
    "p_x_given_neg = p_x_given_y(train_df, vocabulary, 'neg', epsilon=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e516fd7a1c396f25022e90789314651",
     "grade": true,
     "grade_id": "p_x_given_y-test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(p_x_given_neg['bad'], 3) == 0.307\n",
    "assert round(p_x_given_pos['bad'], 3) == 0.139\n",
    "\n",
    "# sanity check "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the top values for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top p(x|pos)\n",
      "[('great', 0.3118811881188119), ('most', 0.2871287128712871), ('best', 0.28217821782178215), ('also', 0.27722772277227725), ('well', 0.27722772277227725), ('watch', 0.26732673267326734), ('we', 0.26732673267326734), ('people', 0.2623762376237624), ('many', 0.25742574257425743), ('too', 0.24752475247524752), ('then', 0.24257425742574257), ('its', 0.2376237623762376), ('think', 0.2376237623762376), ('were', 0.2376237623762376), ('does', 0.23267326732673269)]\n",
      "top p(x|neg)\n",
      "[('bad', 0.3069306930693069), ('made', 0.2722772277227723), ('make', 0.2722772277227723), ('how', 0.26732673267326734), ('were', 0.26732673267326734), ('because', 0.2623762376237624), ('into', 0.2623762376237624), ('then', 0.2623762376237624), ('being', 0.25742574257425743), ('could', 0.25742574257425743), (\"don't\", 0.2524752475247525), ('way', 0.24752475247524752), ('ever', 0.24257425742574257), ('them', 0.24257425742574257), ('too', 0.24257425742574257)]\n"
     ]
    }
   ],
   "source": [
    "print('top p(x|pos)')\n",
    "print(sorted(p_x_given_pos.items(), key=lambda x: -x[1])[:15])\n",
    "\n",
    "print('top p(x|neg)')\n",
    "print(sorted(p_x_given_neg.items(), key=lambda x: -x[1])[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense to see things like `great` and `best` in the positive class and `bad` in the negative class, but both distributions are dominated by very common terms -- e.g., `too` is very common in both classes.\n",
    "\n",
    "To get a better sense of the relative frequency by class, we can simply subtract $p(x|pos)-p(x|neg)$ to find terms that are relatively more frequent in the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive terms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1794</td>\n",
       "      <td>great</td>\n",
       "      <td>0.148515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>454</td>\n",
       "      <td>best</td>\n",
       "      <td>0.133663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4344</td>\n",
       "      <td>watch</td>\n",
       "      <td>0.103960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4464</td>\n",
       "      <td>worth</td>\n",
       "      <td>0.099010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>again</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>687</td>\n",
       "      <td>characters</td>\n",
       "      <td>0.079208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>also</td>\n",
       "      <td>0.079208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2623</td>\n",
       "      <td>most</td>\n",
       "      <td>0.079208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4377</td>\n",
       "      <td>well</td>\n",
       "      <td>0.074257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>man</td>\n",
       "      <td>0.074257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  pos_score\n",
       "1794       great   0.148515\n",
       "454         best   0.133663\n",
       "4344       watch   0.103960\n",
       "4464       worth   0.099010\n",
       "161        again   0.084158\n",
       "687   characters   0.079208\n",
       "207         also   0.079208\n",
       "2623        most   0.079208\n",
       "4377        well   0.074257\n",
       "2450         man   0.074257"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative terms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>bad</td>\n",
       "      <td>-0.168317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4463</td>\n",
       "      <td>worst</td>\n",
       "      <td>-0.163366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2745</td>\n",
       "      <td>nothing</td>\n",
       "      <td>-0.143564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3978</td>\n",
       "      <td>terrible</td>\n",
       "      <td>-0.108911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4405</td>\n",
       "      <td>why</td>\n",
       "      <td>-0.099010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1402</td>\n",
       "      <td>ever</td>\n",
       "      <td>-0.099010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4341</td>\n",
       "      <td>waste</td>\n",
       "      <td>-0.099010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>awful</td>\n",
       "      <td>-0.089109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>511</td>\n",
       "      <td>boring</td>\n",
       "      <td>-0.089109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>believe</td>\n",
       "      <td>-0.084158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  pos_score\n",
       "374        bad  -0.168317\n",
       "4463     worst  -0.163366\n",
       "2745   nothing  -0.143564\n",
       "3978  terrible  -0.108911\n",
       "4405       why  -0.099010\n",
       "1402      ever  -0.099010\n",
       "4341     waste  -0.099010\n",
       "365      awful  -0.089109\n",
       "511     boring  -0.089109\n",
       "438    believe  -0.084158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_scores = pd.DataFrame([{'word':w, 'pos_score': p_x_given_pos[w] - p_x_given_neg[w]} for w in vocabulary])\n",
    "print('positive terms')\n",
    "display(word_scores.sort_values('pos_score', ascending=False).head(10))\n",
    "\n",
    "print('negative terms')\n",
    "display(word_scores.sort_values('pos_score', ascending=True).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These make more sense, though notice we still have some surprising words in the top 10 (e.g., `also`, `man`).\n",
    "\n",
    "Let's stop and think some more about what smoothing is doing. Below we try different values of $\\epsilon$ and print the top 5 terms for the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('great', 0.3118811881188119), ('most', 0.2871287128712871), ('best', 0.28217821782178215), ('also', 0.27722772277227725), ('well', 0.27722772277227725)]\n",
      "[('great', 0.3137254901960784), ('most', 0.28921568627450983), ('best', 0.28431372549019607), ('also', 0.27941176470588236), ('well', 0.27941176470588236)]\n",
      "[('great', 0.3155339805825243), ('most', 0.2912621359223301), ('best', 0.28640776699029125), ('also', 0.2815533980582524), ('well', 0.2815533980582524)]\n",
      "[('great', 0.3173076923076923), ('most', 0.2932692307692308), ('best', 0.28846153846153844), ('also', 0.28365384615384615), ('well', 0.28365384615384615)]\n",
      "[('great', 0.319047619047619), ('most', 0.29523809523809524), ('best', 0.2904761904761905), ('also', 0.2857142857142857), ('well', 0.2857142857142857)]\n",
      "[('great', 0.32075471698113206), ('most', 0.2971698113207547), ('best', 0.29245283018867924), ('also', 0.28773584905660377), ('well', 0.28773584905660377)]\n",
      "[('great', 0.32242990654205606), ('most', 0.29906542056074764), ('best', 0.29439252336448596), ('also', 0.2897196261682243), ('well', 0.2897196261682243)]\n",
      "[('great', 0.32407407407407407), ('most', 0.30092592592592593), ('best', 0.2962962962962963), ('also', 0.2916666666666667), ('well', 0.2916666666666667)]\n",
      "[('great', 0.3256880733944954), ('most', 0.30275229357798167), ('best', 0.2981651376146789), ('also', 0.29357798165137616), ('well', 0.29357798165137616)]\n",
      "[('great', 0.32727272727272727), ('most', 0.30454545454545456), ('best', 0.3), ('also', 0.29545454545454547), ('well', 0.29545454545454547)]\n",
      "[('great', 0.3416666666666667), ('most', 0.32083333333333336), ('best', 0.31666666666666665), ('also', 0.3125), ('well', 0.3125)]\n"
     ]
    }
   ],
   "source": [
    "for e in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20]:\n",
    "    ppp = p_x_given_y(train_df, vocabulary, 'pos', epsilon=e)\n",
    "    ppp = sorted(ppp.items(), key=lambda x: -x[1])\n",
    "    print(ppp[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As $\\epsilon$ increases to infinity, what value will $p(x|y)$ converge to? To answer this, just return the value in the method below (e.g., `return 0` or `return 100`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "528827746005dfbd89500fc7acfdf938",
     "grade": false,
     "grade_id": "convergence",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convergence_value():\n",
    "    # return the float value that you think p(x|y) converges to as epsilon approaches infinity.\n",
    "    # YOUR CODE HERE\n",
    "    return 0.5\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bbfb3bc5d6923112cf42f9c636f6b10",
     "grade": true,
     "grade_id": "convergence-test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about this result and how it relates to the event model of Bernoulli Naive Bayes. E.g., a coin flip for each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other quantity we need is $p(y=1)$, the prior probability. Since this is a binary classification task, we know that $p(y=0) = 1-p(y=1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b571161ea05b04c081b23dba954abf66",
     "grade": false,
     "grade_id": "prior",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_prior(df):\n",
    "    \"\"\"\n",
    "    Compute the prior probability p(y=1) given a training set DataFrame.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    train_df_p=df[df['label']=='pos']\n",
    "    p_y_pos=len(train_df_p)/len(df)\n",
    "    return p_y_pos\n",
    "    raise NotImplementedError()\n",
    "\n",
    "prior = compute_prior(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0104d580322e043c1a0ad7733a31919b",
     "grade": true,
     "grade_id": "prior-test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(compute_prior(train_df), 1) == 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's actually classify a document using Naive Bayes. Recall the classification formula:\n",
    "\n",
    "$$\n",
    "p(y=1|\\vec{x}) = \\frac{p(y=1)\\prod_j p(x_{ij}|y=1)}{p(\\vec{x})}\n",
    "$$\n",
    "\n",
    "The product in the numerator must loop over all words in the vocabulary. Recall that:\n",
    "\n",
    "$$\n",
    "p(x_{ij}=0 \\mid y=1) = 1 - p(x_{ij}=1 \\mid y=1)\n",
    "$$\n",
    "\n",
    "Also, to prevent underflow, we'll have to use this equivalence:\n",
    "$$\n",
    "\\log(p(y=1|\\vec{x})) = \\log(p(y=1)) + \\sum_j \\log p(x_{ij}|y=1) - \\log(p(\\vec{x}))\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\log(p(x)) = \\log \\Big( p(\\vec{x}|y=1)p(y=1) + p(\\vec{x}|y=0)p(y=0) \\Big)$$\n",
    "\n",
    "and to get the final answer:\n",
    "$$p(y=1|\\vec{x}) = \\exp \\Big( \\log(p(y=1|\\vec{x})) \\Big)$$\n",
    "(using `math.log` and `math.exp`)\n",
    "\n",
    "\n",
    "Below, implement `log_p_y_given_x_numerator` which computes just the numerator:\n",
    "\n",
    "$$\\log(p(y)) + \\sum_j \\log p(x_{ij}|y)$$\n",
    "\n",
    "Depending on what is passed in for `p_x_given_y` and `prior`, this will compute the numerator either for $y=1$ or $y=0$.\n",
    "\n",
    "This function is then used by `pr_pos_given_x`, which is done for you, to compute $p(y=1|x)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e85f6b626626c0e32db8c5b5148abf4d",
     "grade": false,
     "grade_id": "classify-nb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def log_p_y_given_x_numerator(features, p_x_given_y, prior, vocabulary):\n",
    "    \"\"\"\n",
    "    returns log(p(y)) + \\sum_j \\log p(x_j|y). This is the numerator in the equation\n",
    "    for p(y|x) above.\n",
    "    \n",
    "    note that p_x_given_y and prior can be values for y=1 or y=0, depending on what\n",
    "    is passed in. see usage in pr_pos_given_x below.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    sum_log=0\n",
    "    for key in vocabulary:\n",
    "        if key in features:\n",
    "            temp=p_x_given_y[key]\n",
    "        else:\n",
    "            temp=1-(p_x_given_y[key])\n",
    "        sum_log+=math.log(temp)\n",
    "    log_p_y_given_x_numerator=math.log(prior)+sum_log\n",
    "    return log_p_y_given_x_numerator\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def pr_pos_given_x(features, p_x_given_pos, p_x_given_neg, prior, vocabulary):\n",
    "    \"\"\"\n",
    "    Returns the probability p(y=1|x). This is complete and should not need to be modified.\n",
    "    \"\"\"\n",
    "    pos_numerator = log_p_y_given_x_numerator(features, p_x_given_pos, prior, vocabulary)\n",
    "    neg_numerator = log_p_y_given_x_numerator(features, p_x_given_neg, 1-prior, vocabulary)\n",
    "    # there's an additional log-sum-exp trick to avoid underflow when computing p(x)\n",
    "    # https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/\n",
    "    maxv = max((pos_numerator, neg_numerator))\n",
    "    log_p_x = maxv + math.log(math.exp(pos_numerator-maxv) + math.exp(neg_numerator-maxv))\n",
    "    v = pos_numerator - log_p_x\n",
    "    return math.exp(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "513974b69471d3354a9680e76b2b9679",
     "grade": true,
     "grade_id": "classify-nb-test",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(pr_pos_given_x({'great': 1, 'most': 1, 'best': 1, 'well': 1}, p_x_given_pos, p_x_given_neg, prior, vocabulary), 2) == 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1599e61615fe27ac4849bcca3cb9719",
     "grade": true,
     "grade_id": "classify-nb-test-2",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(pr_pos_given_x({'bad': 1, 'worst': 1, 'terrible': 1}, p_x_given_pos, p_x_given_neg, prior, vocabulary), 3) == 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to read in the testing data, compute features, and classify.\n",
    "\n",
    "Here, we have to be very careful to process the data in the exact same way, to ensure our feature set is the same in both training and testing. This means the tokenizer is the same, and the features should be pruned to those in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>raw_features</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Of the Korean movies I've seen, only three had really stuck with me. The first is the excellent ...</td>\n",
       "      <td>[of, the, korean, movies, i've, seen, only, three, had, really, stuck, with, me, the, first, is,...</td>\n",
       "      <td>{'of': 1, 'the': 1, 'korean': 1, 'movies': 1, 'i've': 1, 'seen': 1, 'only': 1, 'three': 1, 'had'...</td>\n",
       "      <td>{'movies': 1, 'i've': 1, 'seen': 1, 'three': 1, 'stuck': 1, 'excellent': 1, 'horror': 1, 'tale':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>It started off weird, the middle was weird, and the ending was weird, but I really, really liked...</td>\n",
       "      <td>[it, started, off, weird, the, middle, was, weird, and, the, ending, was, weird, but, i, really,...</td>\n",
       "      <td>{'it': 1, 'started': 1, 'off': 1, 'weird': 1, 'the': 1, 'middle': 1, 'was': 1, 'and': 1, 'ending...</td>\n",
       "      <td>{'started': 1, 'off': 1, 'weird': 1, 'middle': 1, 'ending': 1, 'liked': 1, 'modern': 1, 'day': 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   pos   \n",
       "1   pos   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Of the Korean movies I've seen, only three had really stuck with me. The first is the excellent ...   \n",
       "1  It started off weird, the middle was weird, and the ending was weird, but I really, really liked...   \n",
       "\n",
       "                                                                                                tokens  \\\n",
       "0  [of, the, korean, movies, i've, seen, only, three, had, really, stuck, with, me, the, first, is,...   \n",
       "1  [it, started, off, weird, the, middle, was, weird, and, the, ending, was, weird, but, i, really,...   \n",
       "\n",
       "                                                                                          raw_features  \\\n",
       "0  {'of': 1, 'the': 1, 'korean': 1, 'movies': 1, 'i've': 1, 'seen': 1, 'only': 1, 'three': 1, 'had'...   \n",
       "1  {'it': 1, 'started': 1, 'off': 1, 'weird': 1, 'the': 1, 'middle': 1, 'was': 1, 'and': 1, 'ending...   \n",
       "\n",
       "                                                                                              features  \n",
       "0  {'movies': 1, 'i've': 1, 'seen': 1, 'three': 1, 'stuck': 1, 'excellent': 1, 'horror': 1, 'tale':...  \n",
       "1  {'started': 1, 'off': 1, 'weird': 1, 'middle': 1, 'ending': 1, 'liked': 1, 'modern': 1, 'day': 1...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.tsv', sep='\\t')\n",
    "test_df['tokens'] = [tokenize(d, strip_punct=True, ignore_case=True) for d in test_df.text]\n",
    "test_df['raw_features'] = [featurize(t) for t in test_df.tokens]\n",
    "test_df['features'] = [prune_features(vocabulary, f) for f in test_df.raw_features]\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compute $p(y=1|x)$ for each training and testing instance. We'll store the result in a new column called `pr_pos`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>raw_features</th>\n",
       "      <th>features</th>\n",
       "      <th>pr_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Of the Korean movies I've seen, only three had really stuck with me. The first is the excellent ...</td>\n",
       "      <td>[of, the, korean, movies, i've, seen, only, three, had, really, stuck, with, me, the, first, is,...</td>\n",
       "      <td>{'of': 1, 'the': 1, 'korean': 1, 'movies': 1, 'i've': 1, 'seen': 1, 'only': 1, 'three': 1, 'had'...</td>\n",
       "      <td>{'movies': 1, 'i've': 1, 'seen': 1, 'three': 1, 'stuck': 1, 'excellent': 1, 'horror': 1, 'tale':...</td>\n",
       "      <td>0.508402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>It started off weird, the middle was weird, and the ending was weird, but I really, really liked...</td>\n",
       "      <td>[it, started, off, weird, the, middle, was, weird, and, the, ending, was, weird, but, i, really,...</td>\n",
       "      <td>{'it': 1, 'started': 1, 'off': 1, 'weird': 1, 'the': 1, 'middle': 1, 'was': 1, 'and': 1, 'ending...</td>\n",
       "      <td>{'started': 1, 'off': 1, 'weird': 1, 'middle': 1, 'ending': 1, 'liked': 1, 'modern': 1, 'day': 1...</td>\n",
       "      <td>0.975508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   pos   \n",
       "1   pos   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Of the Korean movies I've seen, only three had really stuck with me. The first is the excellent ...   \n",
       "1  It started off weird, the middle was weird, and the ending was weird, but I really, really liked...   \n",
       "\n",
       "                                                                                                tokens  \\\n",
       "0  [of, the, korean, movies, i've, seen, only, three, had, really, stuck, with, me, the, first, is,...   \n",
       "1  [it, started, off, weird, the, middle, was, weird, and, the, ending, was, weird, but, i, really,...   \n",
       "\n",
       "                                                                                          raw_features  \\\n",
       "0  {'of': 1, 'the': 1, 'korean': 1, 'movies': 1, 'i've': 1, 'seen': 1, 'only': 1, 'three': 1, 'had'...   \n",
       "1  {'it': 1, 'started': 1, 'off': 1, 'weird': 1, 'the': 1, 'middle': 1, 'was': 1, 'and': 1, 'ending...   \n",
       "\n",
       "                                                                                              features  \\\n",
       "0  {'movies': 1, 'i've': 1, 'seen': 1, 'three': 1, 'stuck': 1, 'excellent': 1, 'horror': 1, 'tale':...   \n",
       "1  {'started': 1, 'off': 1, 'weird': 1, 'middle': 1, 'ending': 1, 'liked': 1, 'modern': 1, 'day': 1...   \n",
       "\n",
       "     pr_pos  \n",
       "0  0.508402  \n",
       "1  0.975508  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['pr_pos'] = [pr_pos_given_x(f, p_x_given_pos, p_x_given_neg, prior, vocabulary)\n",
    "                      for f in train_df.features]\n",
    "test_df['pr_pos'] = [pr_pos_given_x(f, p_x_given_pos, p_x_given_neg, prior, vocabulary)\n",
    "                     for f in test_df.features]\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll assign the predicted label as positive if the probability is $\\ge .5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>raw_features</th>\n",
       "      <th>features</th>\n",
       "      <th>pr_pos</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Of the Korean movies I've seen, only three had really stuck with me. The first is the excellent ...</td>\n",
       "      <td>[of, the, korean, movies, i've, seen, only, three, had, really, stuck, with, me, the, first, is,...</td>\n",
       "      <td>{'of': 1, 'the': 1, 'korean': 1, 'movies': 1, 'i've': 1, 'seen': 1, 'only': 1, 'three': 1, 'had'...</td>\n",
       "      <td>{'movies': 1, 'i've': 1, 'seen': 1, 'three': 1, 'stuck': 1, 'excellent': 1, 'horror': 1, 'tale':...</td>\n",
       "      <td>0.508402</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>It started off weird, the middle was weird, and the ending was weird, but I really, really liked...</td>\n",
       "      <td>[it, started, off, weird, the, middle, was, weird, and, the, ending, was, weird, but, i, really,...</td>\n",
       "      <td>{'it': 1, 'started': 1, 'off': 1, 'weird': 1, 'the': 1, 'middle': 1, 'was': 1, 'and': 1, 'ending...</td>\n",
       "      <td>{'started': 1, 'off': 1, 'weird': 1, 'middle': 1, 'ending': 1, 'liked': 1, 'modern': 1, 'day': 1...</td>\n",
       "      <td>0.975508</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   pos   \n",
       "1   pos   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Of the Korean movies I've seen, only three had really stuck with me. The first is the excellent ...   \n",
       "1  It started off weird, the middle was weird, and the ending was weird, but I really, really liked...   \n",
       "\n",
       "                                                                                                tokens  \\\n",
       "0  [of, the, korean, movies, i've, seen, only, three, had, really, stuck, with, me, the, first, is,...   \n",
       "1  [it, started, off, weird, the, middle, was, weird, and, the, ending, was, weird, but, i, really,...   \n",
       "\n",
       "                                                                                          raw_features  \\\n",
       "0  {'of': 1, 'the': 1, 'korean': 1, 'movies': 1, 'i've': 1, 'seen': 1, 'only': 1, 'three': 1, 'had'...   \n",
       "1  {'it': 1, 'started': 1, 'off': 1, 'weird': 1, 'the': 1, 'middle': 1, 'was': 1, 'and': 1, 'ending...   \n",
       "\n",
       "                                                                                              features  \\\n",
       "0  {'movies': 1, 'i've': 1, 'seen': 1, 'three': 1, 'stuck': 1, 'excellent': 1, 'horror': 1, 'tale':...   \n",
       "1  {'started': 1, 'off': 1, 'weird': 1, 'middle': 1, 'ending': 1, 'liked': 1, 'modern': 1, 'day': 1...   \n",
       "\n",
       "     pr_pos predicted_label  \n",
       "0  0.508402             pos  \n",
       "1  0.975508             pos  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['predicted_label'] = ['pos' if v >= .5 else 'neg' for v in train_df.pr_pos]\n",
    "test_df['predicted_label'] = ['pos' if v >= .5 else 'neg' for v in test_df.pr_pos]\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compute some quality metrics over the test set. We'll use [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) method from the sklearn library. Please read through the documentation to understand what these metrics are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results on training data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.99      0.99      0.99       200\n",
      "         pos       0.99      0.99      0.99       200\n",
      "\n",
      "    accuracy                           0.99       400\n",
      "   macro avg       0.99      0.99      0.99       400\n",
      "weighted avg       0.99      0.99      0.99       400\n",
      "\n",
      "results on testing data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.76      0.81      0.79       200\n",
      "         pos       0.80      0.74      0.77       200\n",
      "\n",
      "    accuracy                           0.78       400\n",
      "   macro avg       0.78      0.78      0.78       400\n",
      "weighted avg       0.78      0.78      0.78       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('results on training data')\n",
    "print(classification_report(train_df.label, train_df.predicted_label))\n",
    "print('results on testing data')\n",
    "print(classification_report(test_df.label, test_df.predicted_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the overall accuracy is around 78%. Not bad for a simple method!\n",
    "\n",
    "The precision and recall differ a bit by class, with `pos` having higher precision but lower recall. Based on these results, what is the more common type of error: classifying a negative document as positive (false positive) or classifying a positive document as negative (false negative)? **Submit your answer** by returning either \"false positive\" or \"false negative\" in the method below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e81b3713653da78c613115025a62e8e1",
     "grade": false,
     "grade_id": "error-type",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def error_type():\n",
    "    # return either \"false positive\" or \"false negative\"\n",
    "    # YOUR CODE HERE\n",
    "    return 'false negative'\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aacf577ec860d2c389a3d4b4c97f4dc8",
     "grade": true,
     "grade_id": "error-type-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Next we'll look more closely at Logistic Regression. Below is the code from class to perform gradient descent, using negative log likelihood as the error function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(gradient_fn, error_fn, theta,\n",
    "                     learning_rate, D, tolerance, max_iters):\n",
    "    errori = error_fn(theta, D)\n",
    "    iters = 0\n",
    "    trace = [] # for debugging\n",
    "    while True:\n",
    "        iters += 1\n",
    "        theta_cp = copy.copy(theta)\n",
    "        print('\\n\\niteration %d' % iters)\n",
    "        grad = gradient_fn(theta, D)\n",
    "        trace.append((theta.copy(), grad, errori))\n",
    "        print('gradient=', grad)\n",
    "        theta -= learning_rate * grad  # UPDATE!\n",
    "        newerror = error_fn(theta, D)\n",
    "        print('old error=%g   new error=%g  theta=%s\\n\\n' %\n",
    "              (errori, newerror, str(theta)))\n",
    "        error_diff = errori - newerror\n",
    "        # stopping criteria\n",
    "        if error_diff < 0:\n",
    "            learning_rate *= .5\n",
    "            print('error got worse. reducing learning rate to %g' % learning_rate)\n",
    "            theta = theta_cp\n",
    "            errori = error_fn(theta, D)\n",
    "        elif errori - newerror < tolerance:\n",
    "            print('error change is too small')\n",
    "            break\n",
    "        elif iters >= max_iters:\n",
    "            print('max iterations reached')\n",
    "            break\n",
    "        else:\n",
    "            errori = newerror\n",
    "    trace = pd.DataFrame(trace, columns=['theta', 'gradient', 'error'])\n",
    "    display(trace)\n",
    "    plt.plot(trace.error, 'bo-')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('error')\n",
    "    return theta\n",
    "\n",
    "def f(x, theta):\n",
    "    # dot product\n",
    "    return x.dot(theta)\n",
    "\n",
    "def logistic(x, theta):\n",
    "    # logistic function: p(y=1|x)\n",
    "    return 1 / (1 + math.exp(-f(x, theta)))\n",
    "\n",
    "def nll(theta, D):\n",
    "    # negative log likelihood\n",
    "    total = 0\n",
    "    predictions = [] # for debugging\n",
    "    for xi, yi in D:\n",
    "        pred = logistic(xi, theta) if yi==1 else 1-logistic(xi, theta)\n",
    "        total += math.log(pred)\n",
    "        predictions.append((xi, yi, pred, 1-pred))\n",
    "    display(pd.DataFrame(predictions, columns=['x', 'y', 'prediction', 'error']))        \n",
    "    return -total\n",
    "\n",
    "def gradient_logistic(theta, D):\n",
    "    # gradient function for logistic regression\n",
    "    # updated from lecture to use csr_matrix as feature vectors, \n",
    "    # instead of numpy arrays.\n",
    "    result = np.zeros(len(theta), dtype=np.float64)\n",
    "    for xi, yi in D:\n",
    "        p_y_g_x = logistic(xi, theta) if yi==1 else 1-logistic(xi, theta)\n",
    "        error = yi * (1-p_y_g_x)\n",
    "        for j, xij in zip(xi.indices, xi.data):\n",
    "            result[j] += error * xij\n",
    "    return -result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code expects the features of a document to be a `numpy array`, rather than a `dict` like we used in naive bayes.\n",
    "\n",
    "Complete the code below, which creates a numpy array from a feature `dict`. The array should have `1` at location `i` if word `i` is present in the feature dictionary. The order of the array is deterined by the `vocabulary` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b6d76e77c4f2627381ab7b8f1a307d4",
     "grade": false,
     "grade_id": "fv",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def features2array(features, vocabulary):\n",
    "    # YOUR CODE HERE\n",
    "    feature_array=np.zeros(len(vocabulary))\n",
    "    for i in features:\n",
    "        index=vocabulary[i]\n",
    "        feature_array[index]=1\n",
    "    return feature_array\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ecbb5a26c9b3f3e2edb50c53b64aebcf",
     "grade": true,
     "grade_id": "fv-test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "feature_vector = features2array({'great': 1, 'terrible': 1}, vocabulary)\n",
    "assert len(feature_vector) == len(vocabulary)\n",
    "assert feature_vector[vocabulary['great']] == 1.0\n",
    "assert feature_vector[vocabulary['terrible']] == 1.0\n",
    "assert feature_vector[vocabulary['also']] == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This vector representation is very space inefficient. Since most documents only use a small subset of the full vocabulary, most values will be zero in the feature vector. E.g., below is the number of 0 and 1 values stored in the first training document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 4271, 1.0: 248})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(features2array(train_df.features[0], vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will instead use a [`csr_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html), which is a sparse representation of an array. It only stores the non-zero values, along with some indices keeping track of which column each non-zero value correponds to. Below, I've given you the function to do this. We can see that it saves about 33kb just for the first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document contains 248/4519 words\n",
      "dense array requires 36152 bytes, sparse array requires 2984 bytes\n"
     ]
    }
   ],
   "source": [
    "def features2sparse_array(features, vocabulary):\n",
    "    return csr_matrix(features2array(features, vocabulary), shape=(1, len(vocabulary)))\n",
    "\n",
    "dense_array = features2array(train_df.features[0], vocabulary)\n",
    "sparse_array = features2sparse_array(train_df.features[0], vocabulary)\n",
    "print('document contains %d/%d words' % (sparse_array.nnz, len(vocabulary)))\n",
    "print('dense array requires %d bytes, sparse array requires %d bytes' % \n",
    "      (dense_array.nbytes, sparse_array.data.nbytes + sparse_array.indices.nbytes + sparse_array.indptr.nbytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will add these sparse arrays to our training and testing DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>raw_features</th>\n",
       "      <th>features</th>\n",
       "      <th>pr_pos</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Here's another movie that should be loaded into a satellite, fired into space and pointed in the...</td>\n",
       "      <td>4179</td>\n",
       "      <td>[here's, another, movie, that, should, be, loaded, into, a, satellite, fired, into, space, and, ...</td>\n",
       "      <td>{'here's': 1, 'another': 1, 'movie': 1, 'that': 1, 'should': 1, 'be': 1, 'loaded': 1, 'into': 1,...</td>\n",
       "      <td>{'here's': 1, 'another': 1, 'should': 1, 'into': 1, 'fired': 1, 'space': 1, 'pointed': 1, 'direc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pos</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   pos   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Here's another movie that should be loaded into a satellite, fired into space and pointed in the...   \n",
       "\n",
       "   length  \\\n",
       "0    4179   \n",
       "\n",
       "                                                                                                tokens  \\\n",
       "0  [here's, another, movie, that, should, be, loaded, into, a, satellite, fired, into, space, and, ...   \n",
       "\n",
       "                                                                                          raw_features  \\\n",
       "0  {'here's': 1, 'another': 1, 'movie': 1, 'that': 1, 'should': 1, 'be': 1, 'loaded': 1, 'into': 1,...   \n",
       "\n",
       "                                                                                              features  \\\n",
       "0  {'here's': 1, 'another': 1, 'should': 1, 'into': 1, 'fired': 1, 'space': 1, 'pointed': 1, 'direc...   \n",
       "\n",
       "   pr_pos predicted_label  \\\n",
       "0     1.0             pos   \n",
       "\n",
       "                                                                                        feature_vector  \n",
       "0    (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['feature_vector'] = [features2sparse_array(f, vocabulary) for f in train_df.features]\n",
    "test_df['feature_vector'] = [features2sparse_array(f, vocabulary) for f in test_df.features]\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create the full training dataset $D$, which is a list of tuples of the form (feature_vector, label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = [(fv, 1 if label=='pos' else -1) for label, fv in train_df[['label', 'feature_vector']].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create an initial $\\theta$ vector of 0s and call gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction  error  \n",
       "0    1         0.5    0.5  \n",
       "1    1         0.5    0.5  \n",
       "2    1         0.5    0.5  \n",
       "3    1         0.5    0.5  \n",
       "4    1         0.5    0.5  \n",
       "..  ..         ...    ...  \n",
       "395 -1         0.5    0.5  \n",
       "396 -1         0.5    0.5  \n",
       "397 -1         0.5    0.5  \n",
       "398 -1         0.5    0.5  \n",
       "399 -1         0.5    0.5  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration 1\n",
      "gradient= [ 1.5  7.   1.  ...  2.  -0.  -1. ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>6.144175e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.078801e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>6.772415e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.653424e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>2.039909e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999590</td>\n",
       "      <td>4.095672e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.250089e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>9.635950e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.998641</td>\n",
       "      <td>1.358520e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    0.999994  6.144175e-06  \n",
       "1    1    1.000000  1.078801e-10  \n",
       "2    1    0.999932  6.772415e-05  \n",
       "3    1    1.000000  2.653424e-10  \n",
       "4    1    0.999980  2.039909e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.999590  4.095672e-04  \n",
       "396 -1    1.000000  7.250089e-12  \n",
       "397 -1    0.999990  9.635950e-06  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.998641  1.358520e-03  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=277.259   new error=57.0919  theta=[-0.45 -2.1  -0.3  ... -0.6   0.    0.3 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "gradient= [ 1.12503007e-10  6.08090014e-01  5.22029358e-03 ...  7.25008942e-12\n",
      " -5.66213743e-13 -7.68524793e-01]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.668437e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.272405e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.815756e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.892567e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>6.226220e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>2.164517e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.623546e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.806561e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>3.781916e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  2.668437e-07  \n",
       "1    1    1.000000  3.272405e-11  \n",
       "2    1    0.999982  1.815756e-05  \n",
       "3    1    1.000000  9.892567e-10  \n",
       "4    1    0.999938  6.226220e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997835  2.164517e-03  \n",
       "396 -1    1.000000  5.623546e-11  \n",
       "397 -1    0.999982  1.806561e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999622  3.781916e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=57.0919   new error=2.26915  theta=[-4.50000000e-01 -2.28242700e+00 -3.01566088e-01 ... -6.00000000e-01\n",
      "  1.69864123e-13  5.30557438e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 3\n",
      "gradient= [ 4.99190689e-11  1.55915624e-01  2.21251897e-03 ...  5.62354607e-11\n",
      " -8.04001310e-12 -2.09441782e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>5.008462e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.842326e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>2.691565e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.027321e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>5.560356e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.998225</td>\n",
       "      <td>1.774727e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.110279e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.486532e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>3.422142e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    0.999999  5.008462e-07  \n",
       "1    1    1.000000  2.842326e-11  \n",
       "2    1    0.999973  2.691565e-05  \n",
       "3    1    1.000000  9.027321e-10  \n",
       "4    1    0.999944  5.560356e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.998225  1.774727e-03  \n",
       "396 -1    1.000000  3.110279e-11  \n",
       "397 -1    0.999985  1.486532e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999658  3.422142e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=2.26915   new error=1.11721  theta=[-4.50000000e-01 -2.32920169e+00 -3.02229844e-01 ... -6.00000000e-01\n",
      "  2.58186805e-12  5.30620270e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 4\n",
      "gradient= [ 3.02565750e-11  5.71072855e-02  9.62219071e-04 ...  3.11027870e-11\n",
      " -1.54616320e-11 -2.51905434e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.667302e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.075362e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>2.024474e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.866587e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>4.614024e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997677</td>\n",
       "      <td>2.322914e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.947087e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.848752e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>4.879572e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.667302e-07  \n",
       "1    1    1.000000  2.075362e-11  \n",
       "2    1    0.999980  2.024474e-05  \n",
       "3    1    1.000000  6.866587e-10  \n",
       "4    1    0.999954  4.614024e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997677  2.322914e-03  \n",
       "396 -1    1.000000  5.947087e-11  \n",
       "397 -1    0.999982  1.848752e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999512  4.879572e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=1.11721   new error=0.766601  theta=[-4.50000000e-01 -2.34633388e+00 -3.02518509e-01 ... -6.00000000e-01\n",
      "  7.22035765e-12  5.30695842e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 5\n",
      "gradient= [ 4.53608262e-11  6.25837924e-02  1.00747232e-03 ...  5.94708727e-11\n",
      " -7.40985051e-12 -2.09468395e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.472262e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.994560e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>2.017020e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.322225e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>4.502721e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997648</td>\n",
       "      <td>2.352140e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.453738e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>1.912554e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>5.268278e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.472262e-07  \n",
       "1    1    1.000000  1.994560e-11  \n",
       "2    1    0.999980  2.017020e-05  \n",
       "3    1    1.000000  6.322225e-10  \n",
       "4    1    0.999955  4.502721e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997648  2.352140e-03  \n",
       "396 -1    1.000000  6.453738e-11  \n",
       "397 -1    0.999981  1.912554e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999473  5.268278e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.766601   new error=0.639886  theta=[-4.50000000e-01 -2.36510901e+00 -3.02820751e-01 ... -6.00000000e-01\n",
      "  9.44331280e-12  5.30758683e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 6\n",
      "gradient= [ 4.73193706e-11  5.07471474e-02  8.80084437e-04 ...  6.45373754e-11\n",
      " -6.93756164e-12 -2.10481962e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.372844e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.941958e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>2.025213e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.961962e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>4.446400e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997655</td>\n",
       "      <td>2.345415e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.699175e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>1.951607e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999447</td>\n",
       "      <td>5.527080e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.372844e-07  \n",
       "1    1    1.000000  1.941958e-11  \n",
       "2    1    0.999980  2.025213e-05  \n",
       "3    1    1.000000  5.961962e-10  \n",
       "4    1    0.999956  4.446400e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997655  2.345415e-03  \n",
       "396 -1    1.000000  6.699175e-11  \n",
       "397 -1    0.999980  1.951607e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999447  5.527080e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.639886   new error=0.557163  theta=[-4.50000000e-01 -2.38033316e+00 -3.03084777e-01 ... -6.00000000e-01\n",
      "  1.15245813e-11  5.30821827e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 7\n",
      "gradient= [ 4.83829643e-11  4.26650281e-02  7.83216176e-04 ...  6.69917455e-11\n",
      " -6.71129818e-12 -2.12196945e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.308680e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.899636e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>2.036432e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.693455e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>4.411741e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997677</td>\n",
       "      <td>2.323340e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.824008e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>1.978647e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999428</td>\n",
       "      <td>5.716141e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.308680e-07  \n",
       "1    1    1.000000  1.899636e-11  \n",
       "2    1    0.999980  2.036432e-05  \n",
       "3    1    1.000000  5.693455e-10  \n",
       "4    1    0.999956  4.411741e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997677  2.323340e-03  \n",
       "396 -1    1.000000  6.824008e-11  \n",
       "397 -1    0.999980  1.978647e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999428  5.716141e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.557163   new error=0.497484  theta=[-4.50000000e-01 -2.39313267e+00 -3.03319741e-01 ... -6.00000000e-01\n",
      "  1.35379707e-11  5.30885486e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 8\n",
      "gradient= [ 4.90668617e-11  3.68952216e-02  7.07619930e-04 ...  6.82400803e-11\n",
      " -6.57141008e-12 -2.13828285e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.262415e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.862799e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>2.047962e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.480476e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>4.388172e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997707</td>\n",
       "      <td>2.293233e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.882039e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>1.998453e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>5.859960e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.262415e-07  \n",
       "1    1    1.000000  1.862799e-11  \n",
       "2    1    0.999980  2.047962e-05  \n",
       "3    1    1.000000  5.480476e-10  \n",
       "4    1    0.999956  4.388172e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997707  2.293233e-03  \n",
       "396 -1    1.000000  6.882039e-11  \n",
       "397 -1    0.999980  1.998453e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999414  5.859960e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.497484   new error=0.451759  theta=[-4.50000000e-01 -2.40420123e+00 -3.03532027e-01 ... -6.00000000e-01\n",
      "  1.55093938e-11  5.30949635e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 9\n",
      "gradient= [ 4.95387065e-11  3.25744884e-02  6.46762540e-04 ...  6.88203938e-11\n",
      " -6.47304432e-12 -2.15263422e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.226707e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.829603e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.058969e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.304672e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>4.371107e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997741</td>\n",
       "      <td>2.258679e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.899914e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>2.013453e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>5.971693e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.226707e-07  \n",
       "1    1    1.000000  1.829603e-11  \n",
       "2    1    0.999979  2.058969e-05  \n",
       "3    1    1.000000  5.304672e-10  \n",
       "4    1    0.999956  4.371107e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997741  2.258679e-03  \n",
       "396 -1    1.000000  6.899914e-11  \n",
       "397 -1    0.999980  2.013453e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999403  5.971693e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.451759   new error=0.41527  theta=[-4.50000000e-01 -2.41397358e+00 -3.03726056e-01 ... -6.00000000e-01\n",
      "  1.74513071e-11  5.31014214e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 10\n",
      "gradient= [ 4.98769914e-11  2.92152634e-02  5.96541020e-04 ...  6.89991397e-11\n",
      " -6.39754916e-12 -2.16499119e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.197819e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.799116e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.069175e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.155441e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>4.358211e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>2.221696e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.892498e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>2.025067e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>6.059392e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.197819e-07  \n",
       "1    1    1.000000  1.799116e-11  \n",
       "2    1    0.999979  2.069175e-05  \n",
       "3    1    1.000000  5.155441e-10  \n",
       "4    1    0.999956  4.358211e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997778  2.221696e-03  \n",
       "396 -1    1.000000  6.892498e-11  \n",
       "397 -1    0.999980  2.025067e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999394  6.059392e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.41527   new error=0.385282  theta=[-4.50000000e-01 -2.42273816e+00 -3.03905018e-01 ... -6.00000000e-01\n",
      "  1.93705718e-11  5.31079164e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 11\n",
      "gradient= [ 5.01246822e-11  2.65260852e-02  5.54279338e-04 ...  6.89249768e-11\n",
      " -6.33626485e-12 -2.17555280e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.173628e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.770806e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.078511e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.026111e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>4.348170e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997816</td>\n",
       "      <td>2.183502e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.868706e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>2.034196e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999387</td>\n",
       "      <td>6.128381e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.173628e-07  \n",
       "1    1    1.000000  1.770806e-11  \n",
       "2    1    0.999979  2.078511e-05  \n",
       "3    1    1.000000  5.026111e-10  \n",
       "4    1    0.999957  4.348170e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997816  2.183502e-03  \n",
       "396 -1    1.000000  6.868706e-11  \n",
       "397 -1    0.999980  2.034196e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999387  6.128381e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.385282   new error=0.360082  theta=[-4.50000000e-01 -2.43069599e+00 -3.04071302e-01 ... -6.00000000e-01\n",
      "  2.12714513e-11  5.31144430e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 12\n",
      "gradient= [ 5.03080910e-11  2.43225799e-02  5.18152468e-04 ...  6.86870560e-11\n",
      " -6.28341823e-12 -2.18455382e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.152837e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.744338e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.086991e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.912220e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>4.340186e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997855</td>\n",
       "      <td>2.144866e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.834144e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>2.041439e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>6.182386e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.152837e-07  \n",
       "1    1    1.000000  1.744338e-11  \n",
       "2    1    0.999979  2.086991e-05  \n",
       "3    1    1.000000  4.912220e-10  \n",
       "4    1    0.999957  4.340186e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997855  2.144866e-03  \n",
       "396 -1    1.000000  6.834144e-11  \n",
       "397 -1    0.999980  2.041439e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999382  6.182386e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.360082   new error=0.33853  theta=[-4.50000000e-01 -2.43799276e+00 -3.04226748e-01 ... -6.00000000e-01\n",
      "  2.31564767e-11  5.31209967e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 13\n",
      "gradient= [ 5.04440933e-11  2.24824698e-02  4.86867398e-04 ...  6.83414436e-11\n",
      " -6.23678886e-12 -2.19221309e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.134605e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.719469e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.094668e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.810650e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>4.333750e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997894</td>\n",
       "      <td>2.106284e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.792455e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>2.047217e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>6.224122e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.134605e-07  \n",
       "1    1    1.000000  1.719469e-11  \n",
       "2    1    0.999979  2.094668e-05  \n",
       "3    1    1.000000  4.810650e-10  \n",
       "4    1    0.999957  4.333750e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997894  2.106284e-03  \n",
       "396 -1    1.000000  6.792455e-11  \n",
       "397 -1    0.999980  2.047217e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999378  6.224122e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.33853   new error=0.319836  theta=[-4.50000000e-01 -2.44473750e+00 -3.04372808e-01 ... -6.00000000e-01\n",
      "  2.50275134e-11  5.31275733e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 14\n",
      "gradient= [ 5.05439024e-11  2.09214509e-02  4.59478931e-04 ...  6.79245549e-11\n",
      " -6.19393425e-12 -2.19872100e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.118367e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.695999e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.101605e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.719130e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>4.328517e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997932</td>\n",
       "      <td>2.068084e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.746081e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.051830e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>6.255642e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.118367e-07  \n",
       "1    1    1.000000  1.695999e-11  \n",
       "2    1    0.999979  2.101605e-05  \n",
       "3    1    1.000000  4.719130e-10  \n",
       "4    1    0.999957  4.328517e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997932  2.068084e-03  \n",
       "396 -1    1.000000  6.746081e-11  \n",
       "397 -1    0.999979  2.051830e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999374  6.255642e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.319836   new error=0.30343  theta=[-4.50000000e-01 -2.45101394e+00 -3.04510652e-01 ... -6.00000000e-01\n",
      "  2.68856937e-11  5.31341695e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 15\n",
      "gradient= [ 5.06152897e-11  1.95795024e-02  4.35278065e-04 ...  6.74608147e-11\n",
      " -6.15441031e-12 -2.20423906e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.103723e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.673794e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.107870e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.635965e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>4.324247e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997970</td>\n",
       "      <td>2.030479e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.696654e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.055503e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999372</td>\n",
       "      <td>6.278537e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.103723e-07  \n",
       "1    1    1.000000  1.673794e-11  \n",
       "2    1    0.999979  2.107870e-05  \n",
       "3    1    1.000000  4.635965e-10  \n",
       "4    1    0.999957  4.324247e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.997970  2.030479e-03  \n",
       "396 -1    1.000000  6.696654e-11  \n",
       "397 -1    0.999979  2.055503e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999372  6.278537e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.30343   new error=0.28889  theta=[-4.50000000e-01 -2.45688779e+00 -3.04641235e-01 ... -6.00000000e-01\n",
      "  2.87320168e-11  5.31407822e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 16\n",
      "gradient= [ 5.06641396e-11  1.84127229e-02  4.13721361e-04 ...  6.69665434e-11\n",
      " -6.11688478e-12 -2.20890291e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.090385e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.652722e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.113526e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.559848e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>4.320767e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.998006</td>\n",
       "      <td>1.993612e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.645362e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.058405e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>6.294076e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.090385e-07  \n",
       "1    1    1.000000  1.652722e-11  \n",
       "2    1    0.999979  2.113526e-05  \n",
       "3    1    1.000000  4.559848e-10  \n",
       "4    1    0.999957  4.320767e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.998006  1.993612e-03  \n",
       "396 -1    1.000000  6.645362e-11  \n",
       "397 -1    0.999979  2.058405e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999371  6.294076e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.28889   new error=0.275895  theta=[-4.50000000e-01 -2.46241160e+00 -3.04765352e-01 ... -6.00000000e-01\n",
      "  3.05670822e-11  5.31474089e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 17\n",
      "gradient= [ 5.06944486e-11  1.73882551e-02  3.94384567e-04 ...  6.64536204e-11\n",
      " -6.08113560e-12 -2.21282615e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.078135e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.632716e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.118632e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.489760e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>4.317946e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.998042</td>\n",
       "      <td>1.957571e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.592993e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.060667e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999370</td>\n",
       "      <td>6.303285e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.078135e-07  \n",
       "1    1    1.000000  1.632716e-11  \n",
       "2    1    0.999979  2.118632e-05  \n",
       "3    1    1.000000  4.489760e-10  \n",
       "4    1    0.999957  4.317946e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.998042  1.957571e-03  \n",
       "396 -1    1.000000  6.592993e-11  \n",
       "397 -1    0.999979  2.060667e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999370  6.303285e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.275895   new error=0.264196  theta=[-4.50000000e-01 -2.46762808e+00 -3.04883667e-01 ... -6.00000000e-01\n",
      "  3.23914229e-11  5.31540474e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 18\n",
      "gradient= [ 5.07094366e-11  1.64810147e-02  3.76931194e-04 ...  6.59299282e-11\n",
      " -6.04671868e-12 -2.21610408e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.066809e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.613643e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.123242e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.424880e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>4.315684e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.998078</td>\n",
       "      <td>1.922412e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.540146e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.062392e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999369</td>\n",
       "      <td>6.307013e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.066809e-07  \n",
       "1    1    1.000000  1.613643e-11  \n",
       "2    1    0.999979  2.123242e-05  \n",
       "3    1    1.000000  4.424880e-10  \n",
       "4    1    0.999957  4.315684e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.998078  1.922412e-03  \n",
       "396 -1    1.000000  6.540146e-11  \n",
       "397 -1    0.999979  2.062392e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999369  6.307013e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.264196   new error=0.253596  theta=[-4.50000000e-01 -2.47257238e+00 -3.04996746e-01 ... -6.00000000e-01\n",
      "  3.42054385e-11  5.31606957e-01]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 19\n",
      "gradient= [ 5.07116571e-11  1.56715178e-02  3.61090647e-04 ...  6.54014620e-11\n",
      " -6.01363404e-12 -2.21881682e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.056278e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.595457e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.127403e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.364549e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>4.313904e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>(0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.998112</td>\n",
       "      <td>1.888164e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>(0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.487233e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>(0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>2.063662e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>(0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>(0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999369</td>\n",
       "      <td>6.305968e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       x  \\\n",
       "0      (0, 4)\\t1.0\\n  (0, 19)\\t1.0\\n  (0, 20)\\t1.0\\n  (0, 117)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 146)\\t1.0...   \n",
       "1      (0, 6)\\t1.0\\n  (0, 17)\\t1.0\\n  (0, 18)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 164)\\t1.0...   \n",
       "2      (0, 86)\\t1.0\\n  (0, 170)\\t1.0\\n  (0, 266)\\t1.0\\n  (0, 374)\\t1.0\\n  (0, 593)\\t1.0\\n  (0, 664)\\t...   \n",
       "3      (0, 137)\\t1.0\\n  (0, 516)\\t1.0\\n  (0, 735)\\t1.0\\n  (0, 751)\\t1.0\\n  (0, 838)\\t1.0\\n  (0, 945)\\...   \n",
       "4      (0, 115)\\t1.0\\n  (0, 209)\\t1.0\\n  (0, 257)\\t1.0\\n  (0, 295)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 979)\\...   \n",
       "..                                                                                                   ...   \n",
       "395    (0, 65)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 163)\\t1.0\\n  (0, 441)\\t1.0\\n  (0, 453)\\t1.0\\n  (0, 970)\\t...   \n",
       "396    (0, 24)\\t1.0\\n  (0, 41)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 254)\\t1.0\\n  (0, 260)\\t1.0\\n  (0, 263)\\t1...   \n",
       "397    (0, 36)\\t1.0\\n  (0, 54)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 161)\\t1.0\\n  (0, 469)\\t1.0\\n  (0, 545)\\t1...   \n",
       "398    (0, 43)\\t1.0\\n  (0, 112)\\t1.0\\n  (0, 114)\\t1.0\\n  (0, 122)\\t1.0\\n  (0, 159)\\t1.0\\n  (0, 161)\\t...   \n",
       "399    (0, 151)\\t1.0\\n  (0, 166)\\t1.0\\n  (0, 237)\\t1.0\\n  (0, 460)\\t1.0\\n  (0, 462)\\t1.0\\n  (0, 762)\\...   \n",
       "\n",
       "     y  prediction         error  \n",
       "0    1    1.000000  1.056278e-07  \n",
       "1    1    1.000000  1.595457e-11  \n",
       "2    1    0.999979  2.127403e-05  \n",
       "3    1    1.000000  4.364549e-10  \n",
       "4    1    0.999957  4.313904e-05  \n",
       "..  ..         ...           ...  \n",
       "395 -1    0.998112  1.888164e-03  \n",
       "396 -1    1.000000  6.487233e-11  \n",
       "397 -1    0.999979  2.063662e-05  \n",
       "398 -1    1.000000  0.000000e+00  \n",
       "399 -1    0.999369  6.305968e-04  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old error=0.253596   new error=0.24394  theta=[-4.50000000e-01 -2.47727384e+00 -3.05105074e-01 ... -6.00000000e-01\n",
      "  3.60095287e-11  5.31673521e-01]\n",
      "\n",
      "\n",
      "error change is too small\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>gradient</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.5, 7.0, 1.0, 1.0, -2.5, -1.0, -0.0, 1.5, -0.5, -1.5, -0.0, -1.0, -1.0, -0.0, -1.0, -1.0, -0.0...</td>\n",
       "      <td>277.258872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[-0.44999999999999996, -2.1, -0.3, -0.3, 0.75, 0.3, 0.0, -0.44999999999999996, 0.15, 0.449999999...</td>\n",
       "      <td>[1.1250300691045823e-10, 0.6080900144035751, 0.005220293576283286, -1.7089798024535814, -9.76845...</td>\n",
       "      <td>57.091940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[-0.45000000003375085, -2.2824270043210726, -0.301566088072885, 0.21269394073607445, 0.750029305...</td>\n",
       "      <td>[4.9919068878523376e-11, 0.15591562413947013, 0.0022125189662107747, 0.0735874147765786, -2.5414...</td>\n",
       "      <td>2.269149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[-0.4500000000487266, -2.3292016915629135, -0.3022298437627482, 0.19061771630310087, 0.750036929...</td>\n",
       "      <td>[3.0256575023202004e-11, 0.05710728553993605, 0.0009622190706068956, -0.005573665906802527, -3.8...</td>\n",
       "      <td>1.117207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[-0.45000000005780355, -2.346333877224894, -0.3025185094839303, 0.19228981607514162, 0.750048441...</td>\n",
       "      <td>[4.536082620631987e-11, 0.062583792376815, 0.0010074723151668463, 0.030129381566895597, -2.67558...</td>\n",
       "      <td>0.766601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[-0.4500000000714118, -2.3651090149379383, -0.30282075117848034, 0.18325100160507293, 0.75005646...</td>\n",
       "      <td>[4.731937064406111e-11, 0.050747147432130046, 0.0008800844365259852, 0.023892760710169103, -2.66...</td>\n",
       "      <td>0.639886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[-0.4500000000856076, -2.380333159167577, -0.30308477650943816, 0.1760831733920222, 0.7500644521...</td>\n",
       "      <td>[4.838296430165201e-11, 0.04266502806535377, 0.0007832161757491685, 0.019549985213293097, -2.684...</td>\n",
       "      <td>0.557163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>[-0.4500000001001225, -2.3931326675871833, -0.3033197413621629, 0.17021817782803428, 0.750072504...</td>\n",
       "      <td>[4.9066861684821106e-11, 0.036895221592604166, 0.0007076199300303232, 0.01651681398153859, -2.71...</td>\n",
       "      <td>0.497484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>[-0.45000000011484254, -2.4042012340649648, -0.30353202734117196, 0.1652631336335727, 0.75008065...</td>\n",
       "      <td>[4.95387064702868e-11, 0.03257448842867694, 0.0006467625402839516, 0.014298783025016082, -2.7557...</td>\n",
       "      <td>0.451759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>[-0.45000000012970415, -2.413973580593568, -0.30372605610325715, 0.16097349872606787, 0.75008892...</td>\n",
       "      <td>[4.987699142589008e-11, 0.029215263415339643, 0.0005965410197098509, 0.012611056048320912, -2.79...</td>\n",
       "      <td>0.415270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>[-0.45000000014466723, -2.4227381596181696, -0.3039050184091701, 0.15719018191157158, 0.75009731...</td>\n",
       "      <td>[5.0124682182683955e-11, 0.026526085212521644, 0.0005542793377668609, 0.01128540410003287, -2.83...</td>\n",
       "      <td>0.385282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>[-0.45000000015970465, -2.4306959851819263, -0.30407130221050016, 0.15380456068156173, 0.7501058...</td>\n",
       "      <td>[5.030809102635203e-11, 0.024322579945733613, 0.0005181524676524107, 0.01021723109847783, -2.874...</td>\n",
       "      <td>0.360082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>[-0.4500000001747971, -2.4379927591656463, -0.3042267479507959, 0.1507393913520184, 0.7501144400...</td>\n",
       "      <td>[5.044409334686861e-11, 0.022482469785314763, 0.0004868673978604132, 0.009338365347638211, -2.91...</td>\n",
       "      <td>0.338530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>[-0.4500000001899303, -2.444737500101241, -0.30437280817015405, 0.14793788174772693, 0.750123181...</td>\n",
       "      <td>[5.0543902396782414e-11, 0.02092145087683417, 0.00045947893105158233, 0.008602574528783324, -2.9...</td>\n",
       "      <td>0.319836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>[-0.45000000020509345, -2.451013935364291, -0.3045106518494695, 0.14535710938909194, 0.750132038...</td>\n",
       "      <td>[5.061528973726581e-11, 0.019579502360206114, 0.0004352780648004817, 0.007977447162176188, -2.99...</td>\n",
       "      <td>0.303430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>[-0.45000000022027803, -2.456887786072353, -0.3046412352689097, 0.14296387524043908, 0.750141009...</td>\n",
       "      <td>[5.066413955034932e-11, 0.018412722946980153, 0.00041372136087047817, 0.0074396165959560445, -3....</td>\n",
       "      <td>0.288890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>[-0.45000000023547726, -2.462411602956447, -0.30476535167717084, 0.14073199026165226, 0.75015009...</td>\n",
       "      <td>[5.0694448638921585e-11, 0.017388255140633024, 0.00039438456698681623, 0.00697183004804014, -3.0...</td>\n",
       "      <td>0.275895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>[-0.4500000002506856, -2.467628079498637, -0.3048836670472669, 0.1386404412472402, 0.75015928234...</td>\n",
       "      <td>[5.0709436649754025e-11, 0.01648101469576435, 0.0003769311935941655, 0.0065610834144725905, -3.0...</td>\n",
       "      <td>0.264196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>[-0.4500000002658984, -2.4725723839073663, -0.30499674640534513, 0.13667211622289843, 0.75016858...</td>\n",
       "      <td>[5.0711657095803275e-11, 0.01567151777150977, 0.00036109064660416745, 0.006197396642796393, -3.1...</td>\n",
       "      <td>0.253596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  theta  \\\n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1   [-0.44999999999999996, -2.1, -0.3, -0.3, 0.75, 0.3, 0.0, -0.44999999999999996, 0.15, 0.449999999...   \n",
       "2   [-0.45000000003375085, -2.2824270043210726, -0.301566088072885, 0.21269394073607445, 0.750029305...   \n",
       "3   [-0.4500000000487266, -2.3292016915629135, -0.3022298437627482, 0.19061771630310087, 0.750036929...   \n",
       "4   [-0.45000000005780355, -2.346333877224894, -0.3025185094839303, 0.19228981607514162, 0.750048441...   \n",
       "5   [-0.4500000000714118, -2.3651090149379383, -0.30282075117848034, 0.18325100160507293, 0.75005646...   \n",
       "6   [-0.4500000000856076, -2.380333159167577, -0.30308477650943816, 0.1760831733920222, 0.7500644521...   \n",
       "7   [-0.4500000001001225, -2.3931326675871833, -0.3033197413621629, 0.17021817782803428, 0.750072504...   \n",
       "8   [-0.45000000011484254, -2.4042012340649648, -0.30353202734117196, 0.1652631336335727, 0.75008065...   \n",
       "9   [-0.45000000012970415, -2.413973580593568, -0.30372605610325715, 0.16097349872606787, 0.75008892...   \n",
       "10  [-0.45000000014466723, -2.4227381596181696, -0.3039050184091701, 0.15719018191157158, 0.75009731...   \n",
       "11  [-0.45000000015970465, -2.4306959851819263, -0.30407130221050016, 0.15380456068156173, 0.7501058...   \n",
       "12  [-0.4500000001747971, -2.4379927591656463, -0.3042267479507959, 0.1507393913520184, 0.7501144400...   \n",
       "13  [-0.4500000001899303, -2.444737500101241, -0.30437280817015405, 0.14793788174772693, 0.750123181...   \n",
       "14  [-0.45000000020509345, -2.451013935364291, -0.3045106518494695, 0.14535710938909194, 0.750132038...   \n",
       "15  [-0.45000000022027803, -2.456887786072353, -0.3046412352689097, 0.14296387524043908, 0.750141009...   \n",
       "16  [-0.45000000023547726, -2.462411602956447, -0.30476535167717084, 0.14073199026165226, 0.75015009...   \n",
       "17  [-0.4500000002506856, -2.467628079498637, -0.3048836670472669, 0.1386404412472402, 0.75015928234...   \n",
       "18  [-0.4500000002658984, -2.4725723839073663, -0.30499674640534513, 0.13667211622289843, 0.75016858...   \n",
       "\n",
       "                                                                                               gradient  \\\n",
       "0   [1.5, 7.0, 1.0, 1.0, -2.5, -1.0, -0.0, 1.5, -0.5, -1.5, -0.0, -1.0, -1.0, -0.0, -1.0, -1.0, -0.0...   \n",
       "1   [1.1250300691045823e-10, 0.6080900144035751, 0.005220293576283286, -1.7089798024535814, -9.76845...   \n",
       "2   [4.9919068878523376e-11, 0.15591562413947013, 0.0022125189662107747, 0.0735874147765786, -2.5414...   \n",
       "3   [3.0256575023202004e-11, 0.05710728553993605, 0.0009622190706068956, -0.005573665906802527, -3.8...   \n",
       "4   [4.536082620631987e-11, 0.062583792376815, 0.0010074723151668463, 0.030129381566895597, -2.67558...   \n",
       "5   [4.731937064406111e-11, 0.050747147432130046, 0.0008800844365259852, 0.023892760710169103, -2.66...   \n",
       "6   [4.838296430165201e-11, 0.04266502806535377, 0.0007832161757491685, 0.019549985213293097, -2.684...   \n",
       "7   [4.9066861684821106e-11, 0.036895221592604166, 0.0007076199300303232, 0.01651681398153859, -2.71...   \n",
       "8   [4.95387064702868e-11, 0.03257448842867694, 0.0006467625402839516, 0.014298783025016082, -2.7557...   \n",
       "9   [4.987699142589008e-11, 0.029215263415339643, 0.0005965410197098509, 0.012611056048320912, -2.79...   \n",
       "10  [5.0124682182683955e-11, 0.026526085212521644, 0.0005542793377668609, 0.01128540410003287, -2.83...   \n",
       "11  [5.030809102635203e-11, 0.024322579945733613, 0.0005181524676524107, 0.01021723109847783, -2.874...   \n",
       "12  [5.044409334686861e-11, 0.022482469785314763, 0.0004868673978604132, 0.009338365347638211, -2.91...   \n",
       "13  [5.0543902396782414e-11, 0.02092145087683417, 0.00045947893105158233, 0.008602574528783324, -2.9...   \n",
       "14  [5.061528973726581e-11, 0.019579502360206114, 0.0004352780648004817, 0.007977447162176188, -2.99...   \n",
       "15  [5.066413955034932e-11, 0.018412722946980153, 0.00041372136087047817, 0.0074396165959560445, -3....   \n",
       "16  [5.0694448638921585e-11, 0.017388255140633024, 0.00039438456698681623, 0.00697183004804014, -3.0...   \n",
       "17  [5.0709436649754025e-11, 0.01648101469576435, 0.0003769311935941655, 0.0065610834144725905, -3.0...   \n",
       "18  [5.0711657095803275e-11, 0.01567151777150977, 0.00036109064660416745, 0.006197396642796393, -3.1...   \n",
       "\n",
       "         error  \n",
       "0   277.258872  \n",
       "1    57.091940  \n",
       "2     2.269149  \n",
       "3     1.117207  \n",
       "4     0.766601  \n",
       "5     0.639886  \n",
       "6     0.557163  \n",
       "7     0.497484  \n",
       "8     0.451759  \n",
       "9     0.415270  \n",
       "10    0.385282  \n",
       "11    0.360082  \n",
       "12    0.338530  \n",
       "13    0.319836  \n",
       "14    0.303430  \n",
       "15    0.288890  \n",
       "16    0.275895  \n",
       "17    0.264196  \n",
       "18    0.253596  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = np.zeros(len(vocabulary))\n",
    "theta = gradient_descent(gradient_logistic, nll, theta, .3, D, .01, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results on training data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      1.00      1.00       200\n",
      "         pos       1.00      1.00      1.00       200\n",
      "\n",
      "    accuracy                           1.00       400\n",
      "   macro avg       1.00      1.00      1.00       400\n",
      "weighted avg       1.00      1.00      1.00       400\n",
      "\n",
      "results on testing data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.79      0.79      0.79       200\n",
      "         pos       0.79      0.80      0.79       200\n",
      "\n",
      "    accuracy                           0.79       400\n",
      "   macro avg       0.79      0.79      0.79       400\n",
      "weighted avg       0.79      0.79      0.79       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print accuracy on training and testing data\n",
    "print('results on training data')\n",
    "train_df['pr_pos_lr'] = [logistic(features2sparse_array(f, vocabulary), theta) for f in train_df.features]\n",
    "train_df['predicted_label_lr'] = ['pos' if v >= .5 else 'neg' for v in train_df.pr_pos_lr]\n",
    "print(classification_report(train_df.label, train_df.predicted_label_lr))\n",
    "\n",
    "print('results on testing data')\n",
    "test_df['pr_pos_lr'] = [logistic(features2sparse_array(f, vocabulary), theta) for f in test_df.features]\n",
    "test_df['predicted_label_lr'] = ['pos' if v >= .5 else 'neg' for v in test_df.pr_pos_lr]\n",
    "print(classification_report(test_df.label, test_df.predicted_label_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the classifier has perfect accuracy on the training data, and similar accuracy as naive bayes on the test data.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Now, let's inspect the $\\theta$ coefficients. Here are the largest and smallest values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great 3.9849314068672625\n",
      "best 3.5021885924358807\n",
      "worth 3.03503267699398\n",
      "again 2.8509808811500124\n",
      "watch 2.6970337271289457\n",
      "excellent 2.452009979546707\n",
      "characters 2.3105321539993726\n",
      "where 2.305209268892795\n",
      "role 2.230428438006598\n",
      "himself 2.2163805179363893\n",
      "course 2.202118766254539\n",
      "also 2.18438409816463\n",
      "most 2.1577424641319984\n",
      "times 2.0580443799019243\n",
      "man 2.028296057308245\n",
      "\n",
      "worst -4.989780545191388\n",
      "nothing -4.731229882969549\n",
      "bad -4.550875085951399\n",
      "terrible -3.2994496733451992\n",
      "waste -3.0047891911913376\n",
      "boring -2.7572465178605774\n",
      "why -2.753304627428758\n",
      "awful -2.6914029701534026\n",
      "because -2.661547887241208\n",
      "poor -2.5532211617311655\n",
      "believe -2.517191197830231\n",
      "almost -2.482609778237899\n",
      "1 -2.477273839238819\n",
      "looks -2.4735308515133188\n",
      "being -2.357639101274552\n"
     ]
    }
   ],
   "source": [
    "# print top coefficients for each class.\n",
    "reverse_vocab = {i:v for v,i in vocabulary.items()}\n",
    "for i in np.argsort(theta)[::-1][:15]:\n",
    "    print(reverse_vocab[i], theta[i])\n",
    "print()\n",
    "for i in np.argsort(theta)[:15]:\n",
    "    print(reverse_vocab[i], theta[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting coefficients is a good way to understand your data better. For example, the word \"1\" appears to be strongly associated with the negative class. Do some digging in the original data to figure out why. In what context does the number \"1\" appear, and why is it correlated with the negative class? \n",
    "\n",
    "**Write your answer in the cell below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea2b425d55c3f0ea6f31cf639bcfb9f1",
     "grade": true,
     "grade_id": "number-one",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "find out most of the negative review has sentence similar like 'rate 1 out of 10 stars', that might be the reason '1' is correlated with the negative class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mpos       \u001b[0m\n",
      "I read a small ad in some horror magazine in the early nineties about Liebe des Totes (the love of the dead) or something similar. This of course awoke my curiosity so I ordered Nekromantik 1 & 2 and Der Todesking (The Death King). The Nekromantik movies are Ok, even kind of interesting and unique in their approach to the subject Necrophilia (even if they obviously are horror-opera entries rather than intended to invoke fear in the viewers mind, they are actually quite funny.)<br /><br />TODESKING, on the other hand is, in my opinion, one of the best films ever made. It consist of a series of scenes depicting the many facets of death. Death as an enemy; Death as a reliever, Death as the very fysical decomposition of the body. The film is a metaphor over life. It shows how fragile life is and how short our lives are. It reduces its viewers to the childs they (we) actually are. The fact that we cannot really understand the nature of Death, and hence neither the process of dying, is the core message of the film. This is a most realistic film. Never does Buttgereit try to hide death behind white roses or whatever. No matter what moral standards you set up, death is unevitable, and will sooner or later be not a fiction but YOUR reality. This applies to YOU, Dear Reader, like it applies to the viewers of the film. Some juvenile reviewers seem not to grasp this, which is fully excused, since they of course will live forever...<br /><br />This is no exploitation movie. Why? Because death does not exploit us humans. It harvests us. We grow for seven days, then we are brought back to the schopenhauerian state of pre-birth, that is Death. Buttgereit gives us his version of the oldest of tales. Whether you choose to regard it as \"optimistic\" or \"pessimistic\" is up to you. At first glance it may seem very dark. Consider though, that in order for something to live, something else must die. \"Who wants to live forever?\"<br /><br />I believe that when Buttgereit shows a body, that are being consumed by maggots, he shows not only decomposition, but GENERATION of new life. Is it not better to die and give life to maggots and then birds and eventually become soil, than to remain the living dead zombie that is one of the the favorite pets of the genre?<br /><br />When you realize this, you see Der Todesking it its right context.<br /><br />Sieben Tage hat die Woche, siebenmal letzte Stunden. Seven are the days of week (weak, mortal !), seven times the last hour.<br /><br />Dont fear the Reaper, Buttgereit tells us, because the Reaper takes only what is ripe. And apples that are not plucked for food will rot!<br /><br />Have a good life, fellow IMDB'ers !<br /><br />(And watch this film, that compares only to Ingemar Bergmans \"The Seventh Seal\" in terms of depth and universality)\n",
      "\u001b[1mpos       \u001b[0m\n",
      "In all my 60 years of age, I have learned that when we watch a movie there is an identification (whether we want it or not) implicit with an specific character.<br /><br />Sometimes because the character executes certain gesture, sometimes because the character speaks determinate word, or sentence  that we use or that we would like to use  in determinate situation.<br /><br />The movie in question, should be seen by this point of view. Who now find a parking space  in a mall,downtown, or in the street - taken by a car whose driver can't remember to think that he is not the only driver in the world?<br /><br />Who hasn't the urge to \"rubber out\" the ill mannered spat?<br /><br />Haven said that I ask: - Did you identify with DELLA (played by Kim Bassinger)? If your answer is: YES!, then try not to find absurd details  comparatively with life's reality  in the movie, because you'll certainly find the movie ridiculous.<br /><br />Abstractions made, you will see that the movie has moments of surprise, such as: 1- In the sequence in which Della grabs the box of tools in the trunk (does that box contains a gun, and does she haves the guts to use it?); 2- In the sequence in which Terry dies whilst falling; 3- In the sequence in which Della gets attracted by Chuckie's \"mermaid's call\".<br /><br />If you have already seen the movie, or if are planning seeing, keep in mind that there are \"realistic\" movies, \"fiction\" movies, \"political\" movies, and movies in which you can \"wash your soul\"",
      " To exemplify the last one, we can quote: \"Tropa de Elite\".<br /><br />According to newspaper's , there was unanimous applause when BOPE officials take certain attitudes. (As I have seen the movie in DVD, I could not ascertain the audience's reaction)",
      "<br /><br />As for the direction part (Susan Monford), interpretations (Kim Bassinger, Lukas Haas, Craig Scheffer, etc. Edition (William M. Anderson  'Dead Poets Society', 'Green Card'  exceptional edition, 'Robocop 2', etc. It is well situated in context. In a scale of 1(Awful) to 10(Master Piece), I rate \"When She Was Out\" a 7(Regular).\n",
      "\u001b[1mpos       \u001b[0m\n",
      "JAMES STEWART plays an FBI agent who began working with the agency before it was called the FBI and the story involves dealing with the Ku Klux Klan, the Prohibition Era gangsters, World War II German and Japanese spies, etc. A continuously interesting picture covering 40 years of history; far superior to any films being made these days.<br /><br />Of special interest to older viewers familiar with Washington, DC. In a scene about 20 minutes into the movie --- where James Stewart finds out from Vera Miles that she's expecting their first child --- the scene was filmed in Herzog's Seafood Restaurant on the former Washington waterfront, the only movie in which this historic location appears. Shortly after taking office, President Kennedy decided that Southwest Washington, a 99% Black neighborhood, was an eyesore and ought to be torn down. By decree befitting his position of undisputed royalty, the entire area, including the popular waterfront restaurant district, but excluding 3 historic churches; was reduced to rubble. Black residents evicted from their homes relocated as best they could, and without Federal assistance; likewise businesses were simply put out of business, few re-locating. Restaurant Row was converted into a sidewalk, and Washington had no waterfront (restaurants, seafood stands, boats, etc) for about 10 years. As a lifetime resident, the Herzog Restaurant scene was our #1 reason to see this fine movie again.\n",
      "\u001b[1mpos       \u001b[0m\n",
      "I can give you four reasons to see this movie:<br /><br />1. Four of the best filmmakers in the contemporary Mexican cinema.<br /><br />2. Four good stories, related into a big scheme.<br /><br />3. A surprisingly good cast.<br /><br />4. A bitter reflexion about the biggest trouble in this country (and many others).<br /><br />(POSSIBLE SPOILERS)<br /><br />Alejandro Gamboa opens this movie with a good story in a comedic mood about the authority practicing the extortion against regular people and still expecting to be appreciated by its efforts. <br /><br />Then Antonio Serrano gets more dramatic in the second piece with a story heir to the Italian neorealism with a \"Peter and the wolf\"-like anecdote.<br /><br />In the third story, the one that seems more independent from this series even in the context, Carlos Carrera tells us the story of a man being at the wrong place in the wrong moment. But after the recent lynching at Tlahuac and the tradition in this awful matter at the State of Mexico, this story couldn't be more updated.<br /><br />And at the end, Fernando Sariñana returns to the dark humor in the \"grand finale\" in which he puts together the most of the characters from the past sequences in one of the better comedy pieces ever filmed. Reprising the center scene from one of his previous films \"Todo el poder\", Sariñana gives the final lesson of the theme. And by the way, give us the scene that steals the movie with Anna Ciochetti making a brief striptease.<br /><br />Once the movie has ended, you get a bittersweet feeling about having looked at a good movie (and maybe enjoyed it) with a very painful subject. They say that in Mexico people laugh at their own disgrace and this is the best example. This film is a testimony of how Mexicans have learn to live in the middle of a crime state(and perhaps accepted it), between two fires: The criminals and the so-called authorities full of corruption. Even this movie is a wishful thinking because almost all the good people have been a victim of crime and they don't get this unhurt. If you had an assault without a scratch then you're lucky. Meanwhile, don't lose the chance to see this movie, highly recommended.<br /><br />And it's a beautiful life in Mexico...\n",
      "\u001b[1mneg       \u001b[0m\n",
      "I rated this movie a 1 since the plot is so unbelievable unbelievable. Judge for yourself. Be warned, the following will not only give away the plot, but will also spoil your appetite for watching the movie.<br /><br />A computer virus, designed by a frustrated nerd, sends out a code through television screens and computer monitors. When the code - in the form of light - enters the eye it can access the 'electrical system' of your body. What it does is forcing the body cells into excretion of calcium. Within seconds after infection the patient reaches for his neck, develops tunnel vision, his skin will turn white of the calcium, after which he falls and his hand and scull will crack in a cloud of chalk. <br /><br />This virus is very intelligent. When it finds out that a blind computer expert is trying to disassemble the code with a braille output device - operated by hands - the device is set on a very high voltage, which causes severe burning wounds on the skin of the expert's head. The virus also senses aggression against remote controls and the keyboard of an ATM. Fortunately it could be stopped by throwing over outdated desktop pc's in a rack and electrocuting the nerd with his back on a broken computer and his feet in some spilled water.<br /><br />Oh dear...\n",
      "\u001b[1mneg       \u001b[0m\n",
      "I saw this recently on a faded old VHS tape, and remembered it dimly. Looking at it now, it seems charming.<br /><br />When it was first released, it was recognized by pretty much everyone as a spoof of coming out as a gay teenager. To hammer the point home, the mother is seen reading a paperback copy of \"1 Teenager In 10\", the most popular coming out book of the time. David Warner hams it up as the persecuting vampire hunter [= gay-hating evangelist], who is of course a self-loathing closet case. The list of sight gags and in-jokes that were included to make sure nobody missed the point would be too long to go into. The producers were having some good-natured fun, and hoping, no doubt, to lighten-up as well as to enlighten.<br /><br />But I have no clue how a teenage audience would look at this film, nowadays. In some places, where there is education and culture, the terrifying ordeals that gay teens had to go through are a thing of the past. But I'm sure there are plenty of dark, nasty corners of our continent where it's just as bad as it always was.\n",
      "\u001b[1mneg       \u001b[0m\n",
      "The House of the Dead was the worst movie I have ever seen, between the pathetic 'matrix' 360 camera angle attemps and the cheesy acting I fell asleep. I don't think that the director and set manager could decide whether it was raining or not, because there would be rain on one side of the boat and not the other. I would rate this movie a 1 out of 10, (10 being the best, 1 being the worst). Also jumping scenes from the movie to the game was really annoying, it makes you wonder if they were just making up for lose time. I beg anyone who reads this, NOT TO SEE IT. It's not worth the time.\n",
      "\u001b[1mneg       \u001b[0m\n",
      "I wont take too much time here, just wanted to state that Darkman 3 is awesome. I have all 3 on DVD, added these to my collection of DVD movie sets. Darkman ranks up there with the best, like Indiana Jones, Aliens, Star Wars, Die hard, you get the point. There isn't too many good horror, thriller, sets out there. Many thanks to the whole crew, and set for giving us the Darkman trilogy. By the way if your wondering how I came across this one on DVD. I purchased it through the internet, it is however region 4, as you know most US DVD players are region 1. If you own a Sony Playstation 2, you have the best DVD player since it is an all region player. Just go to set up then choose witch region setting you want ( 1-9 ).\n",
      "\u001b[1mneg       \u001b[0m\n",
      "Usually I'm a bit of a fan of the bad eighties & early nineties film featuring now has beens...but this film is so incredibly terrible that it was a real endurance test to sit through. Guys dressing up as girls has been done to death - but never so pathetically. Corey Haim's performance was abysmal as usual, Nicole Eggert was not much better. This has no redeeming qualities, even if you are a number #1 fan of an actor/actress in this piece of trash - stay away!\n",
      "\u001b[1mneg       \u001b[0m\n",
      "This movie was the beatliest mormon movie made yet. It made the RM & Sons of Provo look like well done films! It was supposed to be funny from what I was told. The best part was the best actor in the movie-Travis Eberhard-if he wasn't in the movie it probably wouldn't have been made! He ruled!<br /><br />10. It wasn't funny 9. It was beat 8. It had Thurl Big T Bailey, who's character made no sense 7. It was made in Provo 6. It didn't make fun of Brokeback 5. It had Larry H. Miller in it 4. It was the 1st movie Clint Howard wasn't funny in 3. Gary Coleman chose the perfect movie 4 a comeback 2. They should have cast at Surreal Life auditions 1. It was made by Halestorm Entertainment!!\n",
      "\u001b[1mneg       \u001b[0m\n",
      "This is one of the worst B slashers I've ever seen in my life. The ending is something you have to see to believe.<br /><br />The movie starts with Harry Standing and Phillip Standing sitting on the stairs with their mother watching their father come down the chimney while dressed in a Santa suit. He puts the presents under the tree, eats the cookies and milk and then goes back up the chimney. Phillip goes to bed but Harry comes down only to find his father dressed in a Santa suit sexually pleasuring his mother. Then, Harry goes up stairs, smashes a snow globe, grabs a shard of glass, and cuts himself.<br /><br />Then you move on to the present. You see Harry. He is a lonely man who sleeps in a Santa suit and watches little kids through a pair of binoculars. He has two books. One book for good kids and the other for bad kids. He writes down everything they do in these books. The guy is a creep. He also works at the Jolly Dream toy factory. His brother Phillip has a family and two kids and lives in a nice house.<br /><br />When Harry finds out that his boss only cares about profits, he goes and collects all the toys and delivers them to a few kids. Then, he travels to a church and kills 4 people. Then he goes to another house and puts presents under the tree. The kids catch him but they go back to bed. So, Harry goes to the bedroom and kills the father and leaves.<br /><br />As he is walking towards a house, a bunch of kids spot him and run up to him. The parent's are nervous and try to get their kids to come back to them so they don't get hurt. How do they know that Harry is the killer? Sure, you have to be suspicious because you never know who it could be. Harry gives the kids presents and the father pulls out a switch blade in an attempt to stab him in front of the kids.<br /><br />When Harry runs off, the townsfolk light torches and follow him to kill him. They don't even know that he is the killer. When Harry reaches his brother's house, his his brother and him have a little talk and Phillip strangles him. He only loses consciousness. Phillip loads Harry back into his van. When Harry wakes up, he takes off.<br /><br />The ending is something I could not believe. Once again, you'll have to see it to believe it.<br /><br />One thing that bugged me was the black Santa. That's right, the man in the Santa suit they saw was a white man. So why did they bring in a black man?<br /><br />Skip this and see Silent Night Deadly Night and Santa's Slay. You'll get your money's worth seeing those two films. They are better than this pile of garbage! I give this movie 1 star out of 10. Wish I could give it 0 stars cause that is what this movie deserves.\n",
      "\u001b[1mneg       \u001b[0m\n",
      "This is one of the worst movies i have seen to date, the best part was Christian J. Meoli \"Leonard\" attempting to act jumping up and down outside the bar, kind-of like i wanted to do on the DVD, to spare the rest of humanity the agony of watching this shitty film. It has a great cast so you keep watching waiting for it to get good, i mean with Sean Astin \"Andrew\" (played his part perfectly, did a great job, too bad it was in this film), Kyra Sedgwick \"Bevan\", Ron Livingston \"Chad\", Renée Zellweger \"Poet\" (they put her name on the cover she has a total of 1 line and less then 4 seconds in the whole movie...<br /><br />If the cast had any dignity, they would go out and buy all the copies of this film and burn them along with Writer / Director George Hickenlooper and Writer John Enbom\n",
      "\u001b[1mneg       \u001b[0m\n",
      "I watched this film because I'm a big fan of River Phoenix and Joaquin Phoenix. I thought I would give their sister a try, Rain Phoenix. I regret checking it out. She was embarrasing and the film just has this weird plot if thats what you want to call it. Sissy was just weird and Jellybean just sits on a toilet who both sleep with this old man in the mountains, whats going on? I have never been so unsatisfied in my life. It was just total rubbish. I can't believe that the actors agreed to do such a waste of film, money, time and space. Have Sissy being 'beautiful' didnt get to me. I thought she was everything but that. Those thumbs were just stupid, and why do we care if she can hitchhike? WHATS THE POINT??? 0 out of 10, shame the poll doesnt have a 0, doesnt even deserve a 1. Hopefully, Rain is better in other films, I forgive her for this one performance, I mean I wouldnt do much better with that film.\n",
      "\u001b[1mneg       \u001b[0m\n",
      "Zombie Review #3<br /><br />**Spoilers**<br /><br />Few films are actually \"so bad they're good\", and Zombi 3 is not just bad, it's wretchedly, unforgivably bad in so many ways that a whole new language may be needed just to describe them all<br /><br />More than that, it's a film credited to Lucio Fulci that even by his standards has absolutely no coherency, sense or reason. However we can't blame Fulci as it wasn't really directed by him but by Bruno Mattei, who doesn't even have Fulci's sense of style to help carry the film. Mattei seems to have brought little to the film but staggering ineptitude.<br /><br />So, I'm ashamed to say how much I enjoyed every worthless minute of Zombi 3. It has no redeeming features - in a genre known for thin characters, weak story, and lack of film making skill, Zombi 3 pushes the boat out but in doing so it's even funnier than Nightmare City.<br /><br />The \"action\" starts when the \"Death 1\" gas is stolen from a military base, and damaged in the escape. Who is the thief, why did he steal it, and why did the US military think that creating cannibalistic legions of the living dead would be a good idea? All these questions and more will fail to be answered in Zombi 3....<br /><br />After hiding out at a hotel, the infected thief goes mad from all the green plastecine growing on his face before being tracked down by the army who somewhat foolishly decide the best way to dispose of his corpse will be to burn it, sending \"Death 1\" up into the atmosphere resulting in... zombie birds! Who then attack people and turn them into zombie people!!! (if zombies are cannibals, why don't the zombie birds just attack other birds?)<br /><br />Then we meet our \"heroes\", a trio of horny GIs and a coachload of girls. There's a couple of other guys with them too, but they're not important - NO ONE is important here. You'll be hard pressed to remember anyone's face, let alone their name or find a reason to care about them. They end up hiding out at the same hotel as the thief (\"a week ago this place was buzzing with life, now it's buzzing with flies!\") but there's no escape from the undead.<br /><br />By this point you'll either be completely sucked in or you'll have turned the damned thing off. The script is so appalling even the greatest acting in the world couldn't save it, so it's just as well they have some of the worst - and not just the human characters, the zombie acting here is an all time low. There's no consistancy in how the zombies behave - some shamble about in the time honored style, others engage in full on fist fights or charge around with machettes, not to mention the zombies who are still able to talk (a gimmick that gives the film it's HORRIFYING TWIST ENDING). They die from gunshots to the chest (rather than the head) and even get knocked out by a good left-hook. How can you punch out a zombie???!!!!! In fact the emphasis on badly done 80s action often makes it resemble an episode of V...<br /><br />The zombies also spend a lot of time hiding, seemingly waiting for hours in ridiculous places on the chance some poor sap will pass by and get the fright of their life. They hide in bushes, in garages, in huts, on roofs, in the water, and even underneath pregnant women. At one point a zombie follows a woman up the stairs. To kill and eat her? No! To push her into the water, those zombies and their wacky sense of humour!<br /><br />There is plenty of gore though. Limbs are hacked, wounds ooze green pus, and there's much in the way of flesh eating and people getting their faces mushed in. There's nothing to match the originals eyeball piercing, but if bad make up effects are your bag you won't be let down.<br /><br />All this and I've not even mentioned the awful music, the inexplicable flying zombie head, the scientist whose acting actually manages to stand out as REALLY bad, or the final chilling punchline.... in an ingenious twist on the originals radio station being overrun by zombies, Zombi 3 gives us an actual zombie DJ!! \"He's gone over to their side!\" our escaping hero's cry, before vowing to continue fighting against the undead in a sequel that sadly never came.<br /><br />Zombi 3 is rubbish - it would be no loss to the world if every single print was destroyed and all records of it's existence erased, yet somehow I feel my life is richer for having seen it.<br /><br />Did I say richer? I meant 88 minutes shorter...\n",
      "\u001b[1mneg       \u001b[0m\n",
      "Trying to cash in on the success of Deal Or No Deal and 1 Versus 100 comes this lame excuse for entertainment - Show Me The Money, in which 12 sexy 'dancers' shimmy out in shiny red hooker attire. A contestant is given the beginning of a phrase, such as \"Which team lost . . .\" with three choices, A, B, or C, each which completes the phrase. The contestant has three chances to give an answer to one of these 3 choices. The host - William Shatner, at his obnoxious smarmiest - asks the contestant if he wants to \"lock into the answer\" and when the contestant says yes, he picks a 'dancer', to whom he yells \"Show me the money!\" She opens a scroll that has an amount, and if his answer was right, he adds that amount to his winnings; if he was wrong, the amount is subtracted. (So theoretically, it is possible for a contestant on this dreary debacle to actually wind up owing Shatner money.) There is also a \"Killer Card\" and if the contestant picks the girl who has that vile scroll, but he has answered properly, nothing happens. If he's answered wrong, the game goes into Sudden Death and has to answer another question. If he gets that one wrong, he leaves with nothing.<br /><br />Before going to commercials, Shatner yells, \"let's dance\" and Shatner, the contestant and the 12 dancers shake booty. At the end of the show, Shatner asks the ladies for \"a last dance\" and they all shake it some more.<br /><br />I give this show 6 episodes at the very most, at which time hopefully this pathetic excuse for a game will be shown the door. (It could've been worse - they could've somehow bribed Cuba Gooding Jr to be the host, although I bet he's a better dancer than 'Shat,' as they call him these days.)<br /><br />7/08: Guess what - I was wrong! It lasted for only 5 episodes. There IS hope for the world.\n",
      "\u001b[1mneg       \u001b[0m\n",
      "The sun was not shining, it was too wet to play, so I went to the movies, that cold, cold, wet date day.<br /><br />\"The Cat in the Hat\" was the name of the flick, and when it was over, my stomach was sick.<br /><br />Mike Myers played the Cat, his humor was lame, and kids needn't see this, the humor was not tame.<br /><br />the film was like drinking milk, from a rabid cow, so it IS fun to have fun, yet the filmmakers didn't know how.<br /><br />This film, in short is atrocious. The acting was bad, the plot was tweaked too much, and the humor was surprisingly very crude.<br /><br />It starts with Conrad and Sally, A rule breaker and a future sheriff. When their Mother has to go to work, she gets Mrs. Kwan to babysit. Possibly the lone funny part in the movie is when Mrs. Kwan is watching a Taiwanese court room, a `la C-SPAN. She soon falls asleep, and here comes the Cat.<br /><br />The film starts to spiral out of control. The Cat came to try to let the kids have some fun. He's got Thing 1 and Thing 2, Who suddenly start trashing the house. He improvises a TV Infomercial, and accidentally slices his tail off. And when the Cat goes full Carmen Miranda, it's not funny. Possibly his only funny disguise is as a hippie activist. And there's a fish who tries warning the kids about the Cat.<br /><br />Too bad he didn't warn us this film was as much fun as sour milk, or chopping your tail off.<br /><br />Soon the kids are outside looking for the family dog, who has the key to a crate on his collar. If the crate is not locked soon, their house will be home to the Cat's universe. Here it gets a little more interesting, but not enough to save the film.<br /><br />The acting, overall, is horrible. Mike Meyers brings his brand of irreverent Austin Powers humor to the Cat, Saying things like \"You dirty ho\" and imagining himself as a woman for the rest of his life after a whack in the testicles while posing as a pinata. Spencer Breslin is great as the trouble-making Conrad, and Dakota Fanning is cute as Sally, though they alone are not enough to save this horrendous Aortic Dissection waiting to kill John Ritter(accident waiting to happen). Alec Baldwin's slick and slimey Lawrence Quinn is disgusting, ever trying to woo the kids mom, who is played by Kelly Preston. And Sean Hayes is Mr. Humberfloob, Mom's boss, and is also the voice of the fish. The latter three are also bland.<br /><br />Overall, if I were a parent I would not take my kids who are into potty humor, cause there's plenty of it and more. Save your $7.00 and see something else. As the late great Dr. Seuss once said,<br /><br />It is fun to have fun, But you have to know how. Really, Universal, stop! Theodore's already turning over in his grave.<br /><br />Like my Mom always says, \"Curiousity killed the Cat\".- The Cat In The Hat * out of *****\n",
      "\u001b[1mneg       \u001b[0m\n",
      "Canadians are too polite to boo but the audience at the Toronto Film Festival left the theater muttering that they would rate this film 0 or 1 on their voting sheets. The premise is that a modern filmmaker is interpreting a 17th century fable about the loves of shepherds and shepherdesses set in the distant past when Druids were the spiritual leaders. Working in three epochs presents many opportunities to introduce anachronisms including silly and impractical clothing and peculiar spiritual rites that involve really bad poetry. Lovers are divided by jealousy and their rigid adherence to idiotic codes of conduct from which cross-dressing and assorted farcical situations arise. The film could have been hilarious as a Monty Python piece, which it too closely resembles, but Rohmer's effort falls very flat. The audience laughed at the sight jokes but otherwise bemoaned the slow pace. The ending comes all in a rush and is truly awful. This is a trivial film and a waste of your movie going time.\n",
      "\u001b[1mneg       \u001b[0m\n",
      "Blonde and Blonder was unfunny.Basically, it was a rip-off girl version of Dumb and Dumber, but less funny, and they used too much background noises and music.WAY TOO MUCH BACKGROUND NOISES AND MUSIC IF YOU ASK ME!!!!It starts out immensely boring, and TOTALLY inane.It doesn't pick up pace anywhere soon, and I was feeling more frustrated as this nonsense carried on.Maybe, the only thing that saved me from giving this movie a 1 was the last 30 minutes.I found it somewhat entertaining and interesting as it neared the end, but that was the only part.Also, I couldn't help but like Pamela Anderson and Denise Richard's characters a little.Even though this movie didn't get any laughs from me, it kept my attention.I wouldn't say to completely avoid this movie, but there are thousands of better films for you to spend your time and money on than Blonde and Blonder.\n",
      "\u001b[1mneg       \u001b[0m\n",
      "I considered myself to be quite melancholy, especially when I watch a great touching and tear-jerking movies. But not for this one (which surprised me!) and it is also really surprising me to see how many people praised this movie so highly.<br /><br />There are several disturbing facts throughout the movies: 1. Despite guilt-ridden Ben's real intention to save 7 lives to redeem his past, I find it disturbing that the film seems encourage this type of suicidal action. Some people may perceive this is a heroic action and some others think he behaves cowardly, in the end this was a disturbing action to me.<br /><br />2. The movie story line is over-dramatized, but the logic is over-simplified. Medically, blood type match is required to be an organ donor. Toward the end of the film we learnt that Emily had rear blood type that limited her chance to get the donor within short time period. Nevertheless, it seemed that Ben had the rare blood type, same as hers which allowed him to be her donor and conveniently, despite the rarity of Ben's blood type, he was able to donate not only his heart, but also his kidney, his cornea and his bone marrow which in all cases require not only matching blood type but also tissue antigen.<br /><br />3. Why the doctors allow Ben's organs being donated despite the jellyfish venom he used to kill himself?<br /><br />I might be over-analyzing the whole story as after all this is just a movie. However, some disturbing facts outlined above hopefully will help you reconsider your plan to go to watch this movie. If you go for a soap-opera type of film, go for it. But it you go seeking for an intelligent entertainment, give this one a miss!\n",
      "\u001b[1mneg       \u001b[0m\n",
      "I'm not a big fan of rom/coms at the best of times. A few have been quite good (check of Dream for an Insomniac), but this one is just more of the same but less.<br /><br />With a running time of 100min, I expect more than 1 laugh every 30mins. The only real belly laugh are when male strangers and friends instinctivly help out Lee's character.<br /><br />All I can say is AVOID. I gaurentee there is at least 10 other movies on the shelf that deserve you $$<br /><br />3 of out 10 (And only cos I'm a big Lee fan)\n",
      "\u001b[1mneg       \u001b[0m\n",
      "Bugs Bunny accidentally ends up at the South Pole while trying to vacation in Florida. Where he meets a little penquin, which he tries to save from an Eskimo. This short tries and the penquin is adorable, but in the end it's a bit too light in the laughs department. The Eskimo isn't really that great of a foil for Bugs and I just seen a lot better Bugs Bunny cartoons frankly, even other shorts when he's paired with other unknown antagonists. So I can't in good conscience recommend this one. However it is nice to see it in it's uncut form. This cartoon is on Disk 3 of the \"Looney Tunes Golden Collection Volume 1\" <br /><br />My Grade: C\n",
      "\u001b[1mneg       \u001b[0m\n",
      "I wanted to see this movie ever since it was first advertised on TV. I went to Tinsel Town to see it Last Night at 7:40. I regret the day that wasted my ticket on this trash when I could of saw something better. The beginning was all a bunch sex trash and cliches. They exaggerated the way love works in reality. All of the girls were stereo types. The boyfriend was too stupid for his own age. The passing gases that the pregnant girl kept having barely got any laughs. The bank robbery was completely boring with gags that have been used in other movies. Their getaway car was an old beat up Chevy van that they claimed that had no breaks. Hey why didn't they get nice girlish vehicle for the robbery instead? It might have boosted the audience opinion about the movie. This movie was very low low low low low budgeted since nothing in there was damaged or destroyed. This movie had a lot of stuff in it that would drive Christian people nuts. Hey I even expected a car chase scene because all bank robbing movies have car chases but I but there was never any. So I rate this movie b which stands for low budgeted and 1 out of ten stars.\n"
     ]
    }
   ],
   "source": [
    "# iterate over the original DataFrame\n",
    "# print all the reviews and corresponding labels containing '1'\n",
    "for rowi, row in train_df.iterrows():\n",
    "    if '1' in row['features']:\n",
    "        print('\\033[1m{:10s}\\033[0m'.format(row['label']))\n",
    "        print(row['text'])\n",
    "# find out most of the negative review has sentence similar like \n",
    "# 'rate 1 out of 10 stars', that might be the reason '1' is correlated with the negative class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, how should we interpret these coefficients? What does a coefficient of $3.98$ tell us about the term `great`?\n",
    "\n",
    "In linear regression, we know that the coefficient $\\theta_i$ represents the strength of the linear relationship between the independent and dependent variables. That is, as the independent variable ($x_i$) increases by one unit, we expect the dependent variable ($y$) to increase by $\\theta_i$.\n",
    "\n",
    "This is a bit more complicated for logistic regression, since the logistic function introduces a non-linear relationship between $x$ and $y$.\n",
    "\n",
    "One approach is to just pass the coefficient through the logistic function. This tells us the probability that a document containing just this single word is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(y=1|great)=0.982\n",
      "p(y=1|terrible)=0.036\n"
     ]
    }
   ],
   "source": [
    "def logistic_single(x):\n",
    "    return 1 / (1+math.exp(-x))\n",
    "\n",
    "\n",
    "print(\"p(y=1|great)=%.3f\" % logistic_single(theta[vocabulary['great']]))\n",
    "print(\"p(y=1|terrible)=%.3f\" % logistic_single(theta[vocabulary['terrible']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn\n",
    "\n",
    "Now, we did all this the hard way to understand how this works. Of course, there are libraries that do most of these steps for us. E.g., [`sklearn`](https://scikit-learn.org/stable/index.html) is a popular machine learning library; a good tutorial is [here](https://www.datacamp.com/community/tutorials/machine-learning-python).\n",
    "\n",
    "For example, the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html?highlight=countvectorizer#sklearn.feature_extraction.text.CountVectorizer) class in sklearn provides a way to extract tokens and features from raw text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train is a csr_matrix with 400 rows and 4525 columns\n",
      "vec.vocabulary_ maps words to indices. E.g., \"great\" has index 1807\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(max_df=100, min_df=2, binary=True)\n",
    "X_train = vec.fit_transform(train_df.text)\n",
    "X_test = vec.transform(test_df.text)\n",
    "print('X_train is a csr_matrix with %d rows and %d columns' % (X_train.shape[0], X_train.shape[1]))\n",
    "print('vec.vocabulary_ maps words to indices. E.g., \"great\" has index %d' % vec.vocabulary_['great'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn has a number of classifiers implemented, including [Bernoulli](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html?highlight=bernoulli#sklearn.naive_bayes.BernoulliNB) and [Multinomial](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomial#sklearn.naive_bayes.MultinomialNB) Naive Bayes, and [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.76      0.82      0.79       200\n",
      "         pos       0.80      0.73      0.77       200\n",
      "\n",
      "    accuracy                           0.78       400\n",
      "   macro avg       0.78      0.78      0.78       400\n",
      "weighted avg       0.78      0.78      0.78       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB(alpha=1)\n",
    "nb.fit(X_train, train_df.label)\n",
    "y_pred = nb.predict(X_test)\n",
    "print(classification_report(test_df.label, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is pretty close to what we got above. There are some small differences in the vocabulary.\n",
    "\n",
    "We can find the word probabilities in `nb.feature_log_prob`, which stores $\\log p(x_i \\mid y)$ for each class. We can exponentiate to get the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(great|y=1)=0.31\n",
      "p(great|y=0)=0.17\n"
     ]
    }
   ],
   "source": [
    "# these should be similar to what we calculated above in our own implementation.\n",
    "great_idx = vec.vocabulary_['great']\n",
    "print('p(great|y=1)=%.2f' % math.exp(nb.feature_log_prob_[1][great_idx]))\n",
    "print('p(great|y=0)=%.2f' % math.exp(nb.feature_log_prob_[0][great_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can similarly fit LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.77      0.77      0.77       200\n",
      "         pos       0.77      0.78      0.77       200\n",
      "\n",
      "    accuracy                           0.77       400\n",
      "   macro avg       0.77      0.77      0.77       400\n",
      "weighted avg       0.77      0.77      0.77       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Since we didn't use any regularization in our implementation above,\n",
    "# I'm setting C to a large number to reduce the effect of the L2 regularizer.\n",
    "lr = LogisticRegression(C=1e10)\n",
    "lr.fit(X_train, train_df.label)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(classification_report(test_df.label, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy is pretty close to our implementation above. \n",
    "\n",
    "We can find the $\\theta$ coefficients in `lr.coef_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta for \"great\" is 1.602\n"
     ]
    }
   ],
   "source": [
    "print('theta for \"great\" is %.3f' % lr.coef_[0][great_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering\n",
    "\n",
    "Now that you understand a bit more about logistic regression and naive bayes, explore `sklearn` for a while to see if you can come up with an approach that has higher test accuracy than we've shown above. A few ground rules:\n",
    "\n",
    "- You can use MultinomialNB, BernoulliNB, or LogisticRegression.\n",
    "- You can modify the tokenization and featurization steps in any way you like.\n",
    "- You can explore any parameters to the constructors of any of the classifiers.\n",
    "\n",
    "In the code cells below, try out different settings to see how it affects test accuracy.\n",
    "\n",
    "In the final written cell, briefly summarize what options you explored, what worked best, what the accuracy was, and why you think your choices improved accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.78      0.81      0.79       200\n",
      "         pos       0.80      0.78      0.79       200\n",
      "\n",
      "    accuracy                           0.79       400\n",
      "   macro avg       0.79      0.79      0.79       400\n",
      "weighted avg       0.79      0.79      0.79       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explore here\n",
    "# multinomialNB\n",
    "vec = CountVectorizer(max_df=100, min_df=2, binary=True)\n",
    "X_train = vec.fit_transform(train_df.text)\n",
    "X_test = vec.transform(test_df.text)\n",
    "\n",
    "# laplace smoothing parameter=1\n",
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(X_train, train_df.label)\n",
    "y_pred = mnb.predict(X_test)\n",
    "print(classification_report(test_df.label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.80      0.81      0.81       200\n",
      "         pos       0.81      0.80      0.81       200\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.81      0.81      0.81       400\n",
      "weighted avg       0.81      0.81      0.81       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# laplace smoothing parameter=10\n",
    "mnb = MultinomialNB(alpha=10)\n",
    "mnb.fit(X_train, train_df.label)\n",
    "y_pred = mnb.predict(X_test)\n",
    "print(classification_report(test_df.label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.80      0.81      0.81       200\n",
      "         pos       0.81      0.80      0.80       200\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.81      0.80      0.80       400\n",
      "weighted avg       0.81      0.81      0.80       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lapace smoothing parameter=50\n",
    "mnb = MultinomialNB(alpha=50)\n",
    "mnb.fit(X_train, train_df.label)\n",
    "y_pred = mnb.predict(X_test)\n",
    "print(classification_report(test_df.label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot laplacian smooth factor vs. accuracy for multinomial naive bayes\n",
    "smooth_factor=[i for i in range(0,200,10)]\n",
    "accur=[]\n",
    "for i in smooth_factor:\n",
    "    mnb = MultinomialNB(alpha=i)\n",
    "    mnb.fit(X_train, train_df.label)\n",
    "    y_pred = mnb.predict(X_test)\n",
    "    accur.append(classification_report(test_df.label, y_pred,output_dict=True)['accuracy'])\n",
    "plt.figure()\n",
    "plt.plot(smooth_factor,accur)\n",
    "plt.xlabel('laplacian smooth factor')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, the accuracy gets improved as increasing laplacian smooth factor around 0-10, but became flat eventually. The multinomial model can achieve the accuracy at 0.81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# similarly, plot laplacian smooth factor vs. accuracy for bernoulli naive bayes\n",
    "smooth_factor=[i for i in range(0,200,10)]\n",
    "accur=[]\n",
    "for i in smooth_factor:\n",
    "    nb = BernoulliNB(alpha=i)\n",
    "    nb.fit(X_train, train_df.label)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    accur.append(classification_report(test_df.label, y_pred,output_dict=True)['accuracy'])\n",
    "plt.figure()\n",
    "plt.plot(smooth_factor,accur)\n",
    "plt.xlabel('laplacian smooth factor')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the same graph for Bernoulli NB, it's surprising that the accuracy get higher as increasing the smooth factor around 0-10, but the accuracy starts to decrease after, the highest accuracy is around 0.75. In general, Multinomial NB does better job than bernoulli NB. I think maybe because the Multinomial is a generalization of Bernoulli distribution, where k=2, n=1. Multinomial NB cares about counts for multiple features that do occur, whereas Bernoulli NB cares about counts for a single feature that do occur and counts for the same feature that do not occur. Multinomial NB will classify a document based on the counts it finds of multiple keywords; whereas Bernoulli NB can only focus on a single keyword, but will also count how many times that keyword does not occur in the document. I am not sure why the smoothing factors in Multinomial NB and Bernoulli NB influence the accuracy so differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f7e6b2fd703e8d53bfed2f1fd844c74",
     "grade": true,
     "grade_id": "engineering",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
